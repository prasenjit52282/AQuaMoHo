{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0daa6e9",
   "metadata": {},
   "source": [
    "# Durgapur Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a927836e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from library.models.rf import RandomForest\n",
    "from library.models.rnn import RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc77d1a",
   "metadata": {},
   "source": [
    "## 70:30 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cea85346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train............\n",
      "{'f1_score': 0.9998161900709147, 'prec_score': 0.9998162319146299, 'rec_score': 0.9998161933645805}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2383\n",
      "           1       1.00      1.00      1.00      2667\n",
      "           2       1.00      1.00      1.00      1777\n",
      "           3       1.00      1.00      1.00      1099\n",
      "           4       1.00      1.00      1.00      2955\n",
      "\n",
      "    accuracy                           1.00     10881\n",
      "   macro avg       1.00      1.00      1.00     10881\n",
      "weighted avg       1.00      1.00      1.00     10881\n",
      "[[2383    0    0    0    0]\n",
      " [   1 2666    0    0    0]\n",
      " [   0    1 1776    0    0]\n",
      " [   0    0    0 1099    0]\n",
      " [   0    0    0    0 2955]]\n",
      "\n",
      "Test............\n",
      "{'f1_score': 0.7535079179556552, 'prec_score': 0.7508724791154862, 'rec_score': 0.7577186963979416}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.85      1022\n",
      "           1       0.75      0.72      0.73      1143\n",
      "           2       0.64      0.61      0.63       761\n",
      "           3       0.50      0.43      0.46       471\n",
      "           4       0.86      0.90      0.88      1267\n",
      "\n",
      "    accuracy                           0.76      4664\n",
      "   macro avg       0.71      0.71      0.71      4664\n",
      "weighted avg       0.75      0.76      0.75      4664\n",
      "[[ 900  119    1    0    2]\n",
      " [ 195  819  113   13    3]\n",
      " [   8  137  465  113   38]\n",
      " [   1   16  110  204  140]\n",
      " [   1    6   34   80 1146]]\n",
      "\n",
      "{'f1_score_train': 0.9998161900709147, 'prec_score_train': 0.9998162319146299, 'rec_score_train': 0.9998161933645805, 'f1_score_test': 0.7535079179556552, 'prec_score_test': 0.7508724791154862, 'rec_score_test': 0.7577186963979416}\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "rf=RandomForest()\n",
    "rf.train_on_files(\"./Data/Dgp/*\",test_size=0.3)\n",
    "print(rf.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e112c1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-21 12:38:31.735982: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-21 12:38:33.140717: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "339/339 [==============================] - 3s 6ms/step - loss: 1.3212 - accuracy: 0.4334 - val_loss: 1.1013 - val_accuracy: 0.5153\n",
      "Epoch 2/20\n",
      "339/339 [==============================] - 1s 4ms/step - loss: 1.0774 - accuracy: 0.5237 - val_loss: 1.0440 - val_accuracy: 0.5416\n",
      "Epoch 3/20\n",
      "339/339 [==============================] - 1s 4ms/step - loss: 1.0397 - accuracy: 0.5405 - val_loss: 1.0246 - val_accuracy: 0.5463\n",
      "Epoch 4/20\n",
      "339/339 [==============================] - 1s 4ms/step - loss: 1.0170 - accuracy: 0.5530 - val_loss: 1.0313 - val_accuracy: 0.5472\n",
      "Epoch 5/20\n",
      "339/339 [==============================] - 1s 4ms/step - loss: 0.9947 - accuracy: 0.5657 - val_loss: 0.9935 - val_accuracy: 0.5545\n",
      "Epoch 6/20\n",
      "339/339 [==============================] - 1s 4ms/step - loss: 0.9820 - accuracy: 0.5685 - val_loss: 0.9846 - val_accuracy: 0.5642\n",
      "Epoch 7/20\n",
      "339/339 [==============================] - 1s 4ms/step - loss: 0.9597 - accuracy: 0.5786 - val_loss: 0.9658 - val_accuracy: 0.5693\n",
      "Epoch 8/20\n",
      "339/339 [==============================] - 1s 4ms/step - loss: 0.9512 - accuracy: 0.5843 - val_loss: 0.9518 - val_accuracy: 0.5803\n",
      "Epoch 9/20\n",
      "339/339 [==============================] - 1s 4ms/step - loss: 0.9382 - accuracy: 0.5941 - val_loss: 0.9506 - val_accuracy: 0.5814\n",
      "Epoch 10/20\n",
      "339/339 [==============================] - 1s 4ms/step - loss: 0.9242 - accuracy: 0.5931 - val_loss: 0.9448 - val_accuracy: 0.5904\n",
      "Epoch 11/20\n",
      "339/339 [==============================] - 1s 4ms/step - loss: 0.9247 - accuracy: 0.5961 - val_loss: 0.9352 - val_accuracy: 0.5894\n",
      "Epoch 12/20\n",
      "339/339 [==============================] - 1s 4ms/step - loss: 0.9119 - accuracy: 0.6002 - val_loss: 0.9240 - val_accuracy: 0.5973\n",
      "Epoch 13/20\n",
      "339/339 [==============================] - 1s 4ms/step - loss: 0.8967 - accuracy: 0.6072 - val_loss: 0.9085 - val_accuracy: 0.6025\n",
      "Epoch 14/20\n",
      "339/339 [==============================] - 1s 4ms/step - loss: 0.8941 - accuracy: 0.6124 - val_loss: 0.9120 - val_accuracy: 0.5988\n",
      "Epoch 15/20\n",
      "339/339 [==============================] - 1s 4ms/step - loss: 0.8750 - accuracy: 0.6112 - val_loss: 0.9123 - val_accuracy: 0.6001\n",
      "Epoch 16/20\n",
      "339/339 [==============================] - 1s 4ms/step - loss: 0.8595 - accuracy: 0.6289 - val_loss: 0.8689 - val_accuracy: 0.6189\n",
      "Epoch 17/20\n",
      "339/339 [==============================] - 1s 4ms/step - loss: 0.8623 - accuracy: 0.6276 - val_loss: 0.8751 - val_accuracy: 0.6197\n",
      "Epoch 18/20\n",
      "339/339 [==============================] - 1s 4ms/step - loss: 0.8486 - accuracy: 0.6344 - val_loss: 0.8817 - val_accuracy: 0.6100\n",
      "Epoch 19/20\n",
      "339/339 [==============================] - 1s 4ms/step - loss: 0.8356 - accuracy: 0.6350 - val_loss: 0.8681 - val_accuracy: 0.6247\n",
      "Epoch 20/20\n",
      "339/339 [==============================] - 1s 4ms/step - loss: 0.8434 - accuracy: 0.6321 - val_loss: 0.8427 - val_accuracy: 0.6309\n",
      "restoring best weights...\n",
      "Train............\n",
      "{'f1_score': 0.6404304542763074, 'prec_score': 0.6446176236182248, 'rec_score': 0.660020308317179}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.72      0.74      2360\n",
      "           1       0.58      0.66      0.61      2644\n",
      "           2       0.51      0.51      0.51      1776\n",
      "           3       0.47      0.13      0.20      1098\n",
      "           4       0.77      0.90      0.83      2955\n",
      "\n",
      "    accuracy                           0.66     10833\n",
      "   macro avg       0.61      0.58      0.58     10833\n",
      "weighted avg       0.64      0.66      0.64     10833\n",
      "[[1697  652    8    0    3]\n",
      " [ 527 1734  330   17   36]\n",
      " [  25  465  906   99  281]\n",
      " [   4  100  353  144  497]\n",
      " [   2   55  182   47 2669]]\n",
      "\n",
      "Test............\n",
      "{'f1_score': 0.6102944522951527, 'prec_score': 0.6130545100481959, 'rec_score': 0.6309216192937123}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.66      0.70      1011\n",
      "           1       0.53      0.62      0.57      1133\n",
      "           2       0.47      0.49      0.48       762\n",
      "           3       0.39      0.10      0.16       471\n",
      "           4       0.76      0.90      0.82      1267\n",
      "\n",
      "    accuracy                           0.63      4644\n",
      "   macro avg       0.58      0.55      0.55      4644\n",
      "weighted avg       0.61      0.63      0.61      4644\n",
      "[[ 669  332    8    1    1]\n",
      " [ 230  707  170    9   17]\n",
      " [  10  224  371   35  122]\n",
      " [   1   54  143   46  227]\n",
      " [   1   10   91   28 1137]]\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm1 (LSTM)                 (None, 18, 32)            6272      \n",
      "_________________________________________________________________\n",
      "dp1 (Dropout)                (None, 18, 32)            0         \n",
      "_________________________________________________________________\n",
      "atten (Attention)            (None, 32)                50        \n",
      "_________________________________________________________________\n",
      "fc (Dense)                   (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 6,487\n",
      "Trainable params: 6,487\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "{'f1_score_train': 0.6404304542763074, 'prec_score_train': 0.6446176236182248, 'rec_score_train': 0.660020308317179, 'f1_score_test': 0.6102944522951527, 'prec_score_test': 0.6130545100481959, 'rec_score_test': 0.6309216192937123}\n"
     ]
    }
   ],
   "source": [
    "#RNN\n",
    "rnn=\\\n",
    "RNN({'lstm1':dict(units=32,seq=True),\n",
    "      'dp1':dict(rate=0.2),\n",
    "      'atten':dict(),\n",
    "      'fc':dict(units=5,activ=\"softmax\")})\n",
    "\n",
    "rnn.train_on_files(\"./Data/Dgp/*\",test_size=0.3,epochs=20,batch_size=32)\n",
    "rnn.model.summary()\n",
    "print(rnn.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8ac7c7",
   "metadata": {},
   "source": [
    "## Overall-one out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fead31d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from library.experiments import overall_experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c68cdd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train............\n",
      "{'f1_score': 0.9996477102638651, 'prec_score': 0.9996481782651517, 'rec_score': 0.9996476702193253}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2070\n",
      "           1       1.00      1.00      1.00      2770\n",
      "           2       1.00      1.00      1.00      1981\n",
      "           3       1.00      1.00      1.00      1240\n",
      "           4       1.00      1.00      1.00      3292\n",
      "\n",
      "    accuracy                           1.00     11353\n",
      "   macro avg       1.00      1.00      1.00     11353\n",
      "weighted avg       1.00      1.00      1.00     11353\n",
      "[[2068    2    0    0    0]\n",
      " [   0 2770    0    0    0]\n",
      " [   0    2 1979    0    0]\n",
      " [   0    0    0 1240    0]\n",
      " [   0    0    0    0 3292]]\n",
      "\n",
      "Test............\n",
      "{'f1_score': 0.7416802480762339, 'prec_score': 0.7417991474434074, 'rec_score': 0.7428435114503816}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      1335\n",
      "           1       0.67      0.65      0.66      1040\n",
      "           2       0.61      0.66      0.63       557\n",
      "           3       0.47      0.43      0.45       330\n",
      "           4       0.86      0.92      0.89       930\n",
      "\n",
      "    accuracy                           0.74      4192\n",
      "   macro avg       0.69      0.69      0.69      4192\n",
      "weighted avg       0.74      0.74      0.74      4192\n",
      "[[1070  261    4    0    0]\n",
      " [ 195  681  148   10    6]\n",
      " [   6   62  369   97   23]\n",
      " [   1    5   69  141  114]\n",
      " [   3    1   19   54  853]]\n",
      "\n",
      "Train............\n",
      "{'f1_score': 0.9997264417053126, 'prec_score': 0.9997264988576209, 'rec_score': 0.9997264271384279}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2489\n",
      "           1       1.00      1.00      1.00      2542\n",
      "           2       1.00      1.00      1.00      1849\n",
      "           3       1.00      1.00      1.00      1165\n",
      "           4       1.00      1.00      1.00      2921\n",
      "\n",
      "    accuracy                           1.00     10966\n",
      "   macro avg       1.00      1.00      1.00     10966\n",
      "weighted avg       1.00      1.00      1.00     10966\n",
      "[[2488    1    0    0    0]\n",
      " [   1 2541    0    0    0]\n",
      " [   0    1 1848    0    0]\n",
      " [   0    0    0 1165    0]\n",
      " [   0    0    0    0 2921]]\n",
      "\n",
      "Test............\n",
      "{'f1_score': 0.6953622468373508, 'prec_score': 0.7128331576941476, 'rec_score': 0.6944747761519983}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.92      0.76       916\n",
      "           1       0.69      0.62      0.65      1268\n",
      "           2       0.55      0.58      0.57       689\n",
      "           3       0.37      0.35      0.36       405\n",
      "           4       0.97      0.77      0.86      1301\n",
      "\n",
      "    accuracy                           0.69      4579\n",
      "   macro avg       0.65      0.65      0.64      4579\n",
      "weighted avg       0.71      0.69      0.70      4579\n",
      "[[ 843   72    1    0    0]\n",
      " [ 441  789   34    4    0]\n",
      " [  13  245  399   29    3]\n",
      " [   0   25  208  142   30]\n",
      " [   0   12   77  205 1007]]\n",
      "\n",
      "Train............\n",
      "{'f1_score': 0.9997567537843546, 'prec_score': 0.9997568479316389, 'rec_score': 0.9997567699043295}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2982\n",
      "           1       1.00      1.00      1.00      3188\n",
      "           2       1.00      1.00      1.00      1932\n",
      "           3       1.00      1.00      1.00      1141\n",
      "           4       1.00      1.00      1.00      3091\n",
      "\n",
      "    accuracy                           1.00     12334\n",
      "   macro avg       1.00      1.00      1.00     12334\n",
      "weighted avg       1.00      1.00      1.00     12334\n",
      "[[2982    0    0    0    0]\n",
      " [   1 3187    0    0    0]\n",
      " [   0    2 1930    0    0]\n",
      " [   0    0    0 1141    0]\n",
      " [   0    0    0    0 3091]]\n",
      "\n",
      "Test............\n",
      "{'f1_score': 0.7617291149394473, 'prec_score': 0.7605756857149908, 'rec_score': 0.7661164746184989}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88       423\n",
      "           1       0.75      0.81      0.77       622\n",
      "           2       0.65      0.67      0.66       606\n",
      "           3       0.50      0.40      0.44       429\n",
      "           4       0.90      0.87      0.88      1131\n",
      "\n",
      "    accuracy                           0.77      3211\n",
      "   macro avg       0.73      0.74      0.73      3211\n",
      "weighted avg       0.76      0.77      0.76      3211\n",
      "[[399  22   0   1   1]\n",
      " [ 77 501  37   5   2]\n",
      " [  2 130 409  41  24]\n",
      " [  2  17 157 171  82]\n",
      " [  1   2  24 124 980]]\n",
      "\n",
      "Train............\n",
      "{'f1_score': 0.9999165373296628, 'prec_score': 0.9999165699533037, 'rec_score': 0.999916541478885}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2674\n",
      "           1       1.00      1.00      1.00      2930\n",
      "           2       1.00      1.00      1.00      1852\n",
      "           3       1.00      1.00      1.00      1164\n",
      "           4       1.00      1.00      1.00      3362\n",
      "\n",
      "    accuracy                           1.00     11982\n",
      "   macro avg       1.00      1.00      1.00     11982\n",
      "weighted avg       1.00      1.00      1.00     11982\n",
      "[[2674    0    0    0    0]\n",
      " [   0 2930    0    0    0]\n",
      " [   0    1 1851    0    0]\n",
      " [   0    0    0 1164    0]\n",
      " [   0    0    0    0 3362]]\n",
      "\n",
      "Test............\n",
      "{'f1_score': 0.698189119930315, 'prec_score': 0.7046400190373548, 'rec_score': 0.707830479932641}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.74      0.80       731\n",
      "           1       0.72      0.71      0.71       880\n",
      "           2       0.68      0.55      0.61       686\n",
      "           3       0.41      0.33      0.37       406\n",
      "           4       0.71      0.98      0.83       860\n",
      "\n",
      "    accuracy                           0.71      3563\n",
      "   macro avg       0.68      0.66      0.66      3563\n",
      "weighted avg       0.70      0.71      0.70      3563\n",
      "[[540 184   5   1   1]\n",
      " [ 80 623 156  11  10]\n",
      " [  3  50 377 175  81]\n",
      " [  0   9  14 135 248]\n",
      " [  0   2   4   7 847]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "rf=RandomForest()\n",
    "df=overall_experiments('overall_rf',rf,'Dgp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa782d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score_train</th>\n",
       "      <th>prec_score_train</th>\n",
       "      <th>rec_score_train</th>\n",
       "      <th>f1_score_test</th>\n",
       "      <th>prec_score_test</th>\n",
       "      <th>rec_score_test</th>\n",
       "      <th>train_dev</th>\n",
       "      <th>test_dev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999648</td>\n",
       "      <td>0.999648</td>\n",
       "      <td>0.999648</td>\n",
       "      <td>0.741680</td>\n",
       "      <td>0.741799</td>\n",
       "      <td>0.742844</td>\n",
       "      <td>[2, 3, 4]</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999726</td>\n",
       "      <td>0.999726</td>\n",
       "      <td>0.999726</td>\n",
       "      <td>0.695362</td>\n",
       "      <td>0.712833</td>\n",
       "      <td>0.694475</td>\n",
       "      <td>[1, 3, 4]</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.999757</td>\n",
       "      <td>0.999757</td>\n",
       "      <td>0.999757</td>\n",
       "      <td>0.761729</td>\n",
       "      <td>0.760576</td>\n",
       "      <td>0.766116</td>\n",
       "      <td>[1, 2, 4]</td>\n",
       "      <td>[3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.999917</td>\n",
       "      <td>0.999917</td>\n",
       "      <td>0.999917</td>\n",
       "      <td>0.698189</td>\n",
       "      <td>0.704640</td>\n",
       "      <td>0.707830</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f1_score_train  prec_score_train  rec_score_train  f1_score_test  \\\n",
       "0        0.999648          0.999648         0.999648       0.741680   \n",
       "1        0.999726          0.999726         0.999726       0.695362   \n",
       "2        0.999757          0.999757         0.999757       0.761729   \n",
       "3        0.999917          0.999917         0.999917       0.698189   \n",
       "\n",
       "   prec_score_test  rec_score_test  train_dev test_dev  \n",
       "0         0.741799        0.742844  [2, 3, 4]      [1]  \n",
       "1         0.712833        0.694475  [1, 3, 4]      [2]  \n",
       "2         0.760576        0.766116  [1, 2, 4]      [3]  \n",
       "3         0.704640        0.707830  [1, 2, 3]      [4]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd053d8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "354/354 [==============================] - 3s 5ms/step - loss: 1.3186 - accuracy: 0.4363 - val_loss: 1.0405 - val_accuracy: 0.5257\n",
      "Epoch 2/2\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 1.0807 - accuracy: 0.5216 - val_loss: 0.9747 - val_accuracy: 0.5770\n",
      "restoring best weights...\n",
      "Train............\n",
      "{'f1_score': 0.48654453802104614, 'prec_score': 0.48050102667153616, 'rec_score': 0.5377809237303132}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.78      0.64      2046\n",
      "           1       0.44      0.36      0.40      2744\n",
      "           2       0.36      0.28      0.31      1981\n",
      "           3       0.22      0.00      0.01      1239\n",
      "           4       0.65      0.89      0.75      3292\n",
      "\n",
      "    accuracy                           0.54     11302\n",
      "   macro avg       0.44      0.46      0.42     11302\n",
      "weighted avg       0.48      0.54      0.49     11302\n",
      "[[1601  390   49    0    6]\n",
      " [1167 1000  421    9  147]\n",
      " [ 173  617  546   12  633]\n",
      " [  16  180  244    6  793]\n",
      " [   7   87  273    0 2925]]\n",
      "\n",
      "Test............\n",
      "{'f1_score': 0.5293690377638018, 'prec_score': 0.5224893791329823, 'rec_score': 0.5770059880239521}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.82      0.74      1325\n",
      "           1       0.42      0.30      0.35      1033\n",
      "           2       0.32      0.27      0.29       557\n",
      "           3       0.25      0.01      0.01       330\n",
      "           4       0.63      0.92      0.75       930\n",
      "\n",
      "    accuracy                           0.58      4175\n",
      "   macro avg       0.46      0.46      0.43      4175\n",
      "weighted avg       0.52      0.58      0.53      4175\n",
      "[[1093  199   28    0    5]\n",
      " [ 480  306  163    4   80]\n",
      " [  39  184  150    2  182]\n",
      " [   1   29   70    2  228]\n",
      " [   0    8   64    0  858]]\n",
      "\n",
      "Epoch 1/2\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 1.0326 - accuracy: 0.5503 - val_loss: 1.0273 - val_accuracy: 0.5416\n",
      "Epoch 2/2\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 1.0095 - accuracy: 0.5622 - val_loss: 1.0082 - val_accuracy: 0.5478\n",
      "restoring best weights...\n",
      "Train............\n",
      "{'f1_score': 0.5227807156748125, 'prec_score': 0.5353359953547001, 'rec_score': 0.5665597801191021}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.73      0.70      2461\n",
      "           1       0.47      0.43      0.45      2519\n",
      "           2       0.40      0.31      0.35      1849\n",
      "           3       0.41      0.03      0.05      1165\n",
      "           4       0.61      0.92      0.73      2921\n",
      "\n",
      "    accuracy                           0.57     10915\n",
      "   macro avg       0.51      0.48      0.46     10915\n",
      "weighted avg       0.54      0.57      0.52     10915\n",
      "[[1796  599   48    3   15]\n",
      " [ 781 1084  399    8  247]\n",
      " [  74  496  580   19  680]\n",
      " [   6   93  237   30  799]\n",
      " [   2   33  179   13 2694]]\n",
      "\n",
      "Test............\n",
      "{'f1_score': 0.5085423972083442, 'prec_score': 0.5222561346540692, 'rec_score': 0.5477860587461639}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.81      0.61       910\n",
      "           1       0.45      0.35      0.40      1258\n",
      "           2       0.35      0.26      0.30       689\n",
      "           3       0.41      0.03      0.06       404\n",
      "           4       0.75      0.87      0.80      1301\n",
      "\n",
      "    accuracy                           0.55      4562\n",
      "   macro avg       0.49      0.46      0.43      4562\n",
      "weighted avg       0.52      0.55      0.51      4562\n",
      "[[ 734  169    3    0    4]\n",
      " [ 673  444  103    3   35]\n",
      " [  93  269  179    2  146]\n",
      " [   4   74  115   12  199]\n",
      " [   7   34  118   12 1130]]\n",
      "\n",
      "Epoch 1/2\n",
      "384/384 [==============================] - 2s 4ms/step - loss: 0.9930 - accuracy: 0.5608 - val_loss: 0.9853 - val_accuracy: 0.5902\n",
      "Epoch 2/2\n",
      "384/384 [==============================] - 2s 4ms/step - loss: 0.9743 - accuracy: 0.5707 - val_loss: 0.9949 - val_accuracy: 0.5798\n",
      "restoring best weights...\n",
      "Train............\n",
      "{'f1_score': 0.5320785387791763, 'prec_score': 0.5682191959294007, 'rec_score': 0.5801514288040381}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.81      0.70      2957\n",
      "           1       0.52      0.35      0.42      3163\n",
      "           2       0.41      0.38      0.39      1932\n",
      "           3       0.63      0.01      0.02      1140\n",
      "           4       0.64      0.93      0.76      3091\n",
      "\n",
      "    accuracy                           0.58     12283\n",
      "   macro avg       0.56      0.50      0.46     12283\n",
      "weighted avg       0.57      0.58      0.53     12283\n",
      "[[2405  477   64    0   11]\n",
      " [1327 1108  529    2  197]\n",
      " [ 150  418  731    3  630]\n",
      " [   9   86  287   12  746]\n",
      " [   7   25  187    2 2870]]\n",
      "\n",
      "Test............\n",
      "{'f1_score': 0.5379722560776236, 'prec_score': 0.5751710755318262, 'rec_score': 0.5901690670006262}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.76      0.73       414\n",
      "           1       0.53      0.42      0.47       614\n",
      "           2       0.40      0.43      0.42       606\n",
      "           3       0.56      0.01      0.02       429\n",
      "           4       0.65      0.92      0.77      1131\n",
      "\n",
      "    accuracy                           0.59      3194\n",
      "   macro avg       0.57      0.51      0.48      3194\n",
      "weighted avg       0.58      0.59      0.54      3194\n",
      "[[ 315   83   13    0    3]\n",
      " [ 115  258  188    1   52]\n",
      " [  13  120  262    2  209]\n",
      " [   4   18  111    5  291]\n",
      " [   2    9   74    1 1045]]\n",
      "\n",
      "Epoch 1/2\n",
      "373/373 [==============================] - 2s 4ms/step - loss: 0.9606 - accuracy: 0.5794 - val_loss: 1.0424 - val_accuracy: 0.5446\n",
      "Epoch 2/2\n",
      "373/373 [==============================] - 2s 4ms/step - loss: 0.9424 - accuracy: 0.5901 - val_loss: 1.0569 - val_accuracy: 0.5406\n",
      "restoring best weights...\n",
      "Train............\n",
      "{'f1_score': 0.5582410976606251, 'prec_score': 0.5788665161076184, 'rec_score': 0.5970161763473305}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.83      0.71      2649\n",
      "           1       0.50      0.41      0.45      2905\n",
      "           2       0.39      0.39      0.39      1852\n",
      "           3       0.56      0.03      0.06      1163\n",
      "           4       0.72      0.89      0.80      3362\n",
      "\n",
      "    accuracy                           0.60     11931\n",
      "   macro avg       0.56      0.51      0.48     11931\n",
      "weighted avg       0.58      0.60      0.56     11931\n",
      "[[2195  420   29    0    5]\n",
      " [1182 1184  430    3  106]\n",
      " [ 125  567  726   13  421]\n",
      " [  12  138  368   35  610]\n",
      " [   7   59  301   12 2983]]\n",
      "\n",
      "Test............\n",
      "{'f1_score': 0.4997554921917255, 'prec_score': 0.5309628473566591, 'rec_score': 0.5445572476029329}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.74      0.69       722\n",
      "           1       0.51      0.44      0.47       872\n",
      "           2       0.39      0.34      0.36       686\n",
      "           3       0.53      0.02      0.04       406\n",
      "           4       0.57      0.90      0.70       860\n",
      "\n",
      "    accuracy                           0.54      3546\n",
      "   macro avg       0.53      0.49      0.45      3546\n",
      "weighted avg       0.53      0.54      0.50      3546\n",
      "[[536 163  23   0   0]\n",
      " [252 380 180   0  60]\n",
      " [ 44 158 231   5 248]\n",
      " [  3  39  86   8 270]\n",
      " [  0   7  75   2 776]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#RNN\n",
    "rnn=RNN({'lstm1':dict(units=32,seq=True),\n",
    "         'dp1':dict(rate=0.2),\n",
    "         'atten':dict(),\n",
    "         'fc':dict(units=5,activ=\"softmax\")})\n",
    "df=overall_experiments('overall_rnn',rnn,'Dgp',epochs=2,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e32456c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score_train</th>\n",
       "      <th>prec_score_train</th>\n",
       "      <th>rec_score_train</th>\n",
       "      <th>f1_score_test</th>\n",
       "      <th>prec_score_test</th>\n",
       "      <th>rec_score_test</th>\n",
       "      <th>train_dev</th>\n",
       "      <th>test_dev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.486545</td>\n",
       "      <td>0.480501</td>\n",
       "      <td>0.537781</td>\n",
       "      <td>0.529369</td>\n",
       "      <td>0.522489</td>\n",
       "      <td>0.577006</td>\n",
       "      <td>[2, 3, 4]</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.522781</td>\n",
       "      <td>0.535336</td>\n",
       "      <td>0.566560</td>\n",
       "      <td>0.508542</td>\n",
       "      <td>0.522256</td>\n",
       "      <td>0.547786</td>\n",
       "      <td>[1, 3, 4]</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.532079</td>\n",
       "      <td>0.568219</td>\n",
       "      <td>0.580151</td>\n",
       "      <td>0.537972</td>\n",
       "      <td>0.575171</td>\n",
       "      <td>0.590169</td>\n",
       "      <td>[1, 2, 4]</td>\n",
       "      <td>[3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.558241</td>\n",
       "      <td>0.578867</td>\n",
       "      <td>0.597016</td>\n",
       "      <td>0.499755</td>\n",
       "      <td>0.530963</td>\n",
       "      <td>0.544557</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f1_score_train  prec_score_train  rec_score_train  f1_score_test  \\\n",
       "0        0.486545          0.480501         0.537781       0.529369   \n",
       "1        0.522781          0.535336         0.566560       0.508542   \n",
       "2        0.532079          0.568219         0.580151       0.537972   \n",
       "3        0.558241          0.578867         0.597016       0.499755   \n",
       "\n",
       "   prec_score_test  rec_score_test  train_dev test_dev  \n",
       "0         0.522489        0.577006  [2, 3, 4]      [1]  \n",
       "1         0.522256        0.547786  [1, 3, 4]      [2]  \n",
       "2         0.575171        0.590169  [1, 2, 4]      [3]  \n",
       "3         0.530963        0.544557  [1, 2, 3]      [4]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f520aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NICE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('myenv': conda)",
   "language": "python",
   "name": "python3812jvsc74a57bd0e47b1a34c05c1e3b83a62d7885c9d1b5ef8a0522d3be0182d0a008ec409b2b3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
