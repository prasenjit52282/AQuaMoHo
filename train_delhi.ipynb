{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0daa6e9",
   "metadata": {},
   "source": [
    "# Durgapur/Delhi Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a927836e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from library.constants import epochs,batch_size\n",
    "from library.models.rf import RandomForest\n",
    "from library.models.rnn import RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "625fbd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "city=\"Delhi\"\n",
    "data_pattern=f\"./Data/{city}/*\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa3a7da",
   "metadata": {},
   "source": [
    "# Model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "badd1446",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_fn=lambda : RandomForest()\n",
    "rnn_model_fn=lambda : RNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc77d1a",
   "metadata": {},
   "source": [
    "## 70:30 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cea85346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train............\n",
      "{'f1_score': 0.9613409017037491, 'prec_score': 0.9621629835629253, 'rec_score': 0.9612640266710034}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96     20455\n",
      "           1       0.93      0.97      0.95     28719\n",
      "           2       0.98      0.93      0.95     15605\n",
      "           3       0.99      0.93      0.96      9180\n",
      "           4       0.99      0.98      0.98     24425\n",
      "\n",
      "    accuracy                           0.96     98384\n",
      "   macro avg       0.97      0.95      0.96     98384\n",
      "weighted avg       0.96      0.96      0.96     98384\n",
      "[[19718   733     3     0     1]\n",
      " [  666 27949    87     2    15]\n",
      " [   80  1000 14455    16    54]\n",
      " [   14   239   175  8555   197]\n",
      " [  168   234   102    25 23896]]\n",
      "\n",
      "Test............\n",
      "{'f1_score': 0.6681327572257096, 'prec_score': 0.6656713028007436, 'rec_score': 0.6735206925174908}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.76      8766\n",
      "           1       0.65      0.72      0.68     12308\n",
      "           2       0.50      0.46      0.48      6688\n",
      "           3       0.41      0.30      0.35      3935\n",
      "           4       0.82      0.81      0.81     10468\n",
      "\n",
      "    accuracy                           0.67     42165\n",
      "   macro avg       0.63      0.61      0.62     42165\n",
      "weighted avg       0.67      0.67      0.67     42165\n",
      "[[6807 1865   54   13   27]\n",
      " [1902 8832 1285  155  134]\n",
      " [ 132 2179 3094  790  493]\n",
      " [  18  399 1097 1187 1234]\n",
      " [ 181  416  615  777 8479]]\n",
      "\n",
      "{'f1_score_train': 0.9613409017037491, 'prec_score_train': 0.9621629835629253, 'rec_score_train': 0.9612640266710034, 'f1_score_test': 0.6681327572257096, 'prec_score_test': 0.6656713028007436, 'rec_score_test': 0.6735206925174908}\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "rf=rf_model_fn()\n",
    "rf.train_on_files(data_pattern,test_size=0.3)\n",
    "print(rf.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e112c1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #RNN\n",
    "rnn=rnn_model_fn()\n",
    "\n",
    "rnn.train_on_files(data_pattern,test_size=0.3,epochs=epochs,batch_size=256)\n",
    "rnn.model.summary()\n",
    "print(rnn.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8ac7c7",
   "metadata": {},
   "source": [
    "## Overall-one out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fead31d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from library.experiments import experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c68cdd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train............\n",
      "{'f1_score': 0.9498756601703726, 'prec_score': 0.9510250895491845, 'rec_score': 0.9498123250161523}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95     27771\n",
      "           1       0.91      0.96      0.94     38240\n",
      "           2       0.96      0.91      0.93     20356\n",
      "           3       0.99      0.90      0.94     11987\n",
      "           4       0.99      0.97      0.98     31658\n",
      "\n",
      "    accuracy                           0.95    130012\n",
      "   macro avg       0.96      0.94      0.95    130012\n",
      "weighted avg       0.95      0.95      0.95    130012\n",
      "[[26638  1125     6     1     1]\n",
      " [ 1182 36824   199     7    28]\n",
      " [  110  1675 18453    33    85]\n",
      " [   25   411   381 10819   351]\n",
      " [  240   398   216    51 30753]]\n",
      "\n",
      "Test............\n",
      "{'f1_score': 0.5857461345828707, 'prec_score': 0.6017123999866483, 'rec_score': 0.5942867988991174}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.86      0.67      1450\n",
      "           1       0.51      0.64      0.57      2787\n",
      "           2       0.43      0.31      0.36      1937\n",
      "           3       0.37      0.23      0.28      1128\n",
      "           4       0.89      0.73      0.80      3235\n",
      "\n",
      "    accuracy                           0.59     10537\n",
      "   macro avg       0.55      0.55      0.54     10537\n",
      "weighted avg       0.60      0.59      0.59     10537\n",
      "[[1242  198    5    0    5]\n",
      " [ 862 1793  114    7   11]\n",
      " [  58 1101  604  109   65]\n",
      " [   2  192  451  261  222]\n",
      " [ 100  207  233  333 2362]]\n",
      "\n",
      "Train............\n",
      "{'f1_score': 0.9496196247644209, 'prec_score': 0.9508174900707056, 'rec_score': 0.9495149860368876}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95     25898\n",
      "           1       0.91      0.96      0.93     37245\n",
      "           2       0.96      0.91      0.93     20842\n",
      "           3       0.99      0.91      0.95     12172\n",
      "           4       0.98      0.97      0.98     32396\n",
      "\n",
      "    accuracy                           0.95    128553\n",
      "   macro avg       0.96      0.94      0.95    128553\n",
      "weighted avg       0.95      0.95      0.95    128553\n",
      "[[24687  1202     5     1     3]\n",
      " [ 1093 35891   216     8    37]\n",
      " [   93  1668 18943    38   100]\n",
      " [   19   390   375 11046   342]\n",
      " [  254   398   201    47 31496]]\n",
      "\n",
      "Test............\n",
      "{'f1_score': 0.6948012849523552, 'prec_score': 0.707975334319528, 'rec_score': 0.692647549183061}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.69      0.78      3323\n",
      "           1       0.69      0.73      0.71      3782\n",
      "           2       0.45      0.56      0.50      1451\n",
      "           3       0.40      0.34      0.37       943\n",
      "           4       0.75      0.85      0.80      2497\n",
      "\n",
      "    accuracy                           0.69     11996\n",
      "   macro avg       0.64      0.63      0.63     11996\n",
      "weighted avg       0.71      0.69      0.69     11996\n",
      "[[2300  967   35    3   18]\n",
      " [ 250 2746  617   84   85]\n",
      " [   1  222  818  223  187]\n",
      " [   2   15  195  320  411]\n",
      " [   5   56  146  165 2125]]\n",
      "\n",
      "Train............\n",
      "{'f1_score': 0.9525910822247552, 'prec_score': 0.9536028731198556, 'rec_score': 0.9524965191079582}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95     27455\n",
      "           1       0.91      0.96      0.94     37859\n",
      "           2       0.96      0.91      0.94     20190\n",
      "           3       0.99      0.92      0.95     11795\n",
      "           4       0.99      0.97      0.98     31260\n",
      "\n",
      "    accuracy                           0.95    128559\n",
      "   macro avg       0.96      0.94      0.95    128559\n",
      "weighted avg       0.95      0.95      0.95    128559\n",
      "[[26337  1112     2     2     2]\n",
      " [ 1125 36501   202     6    25]\n",
      " [   73  1556 18438    41    82]\n",
      " [   13   353   322 10796   311]\n",
      " [  267   387   193    33 30380]]\n",
      "\n",
      "Test............\n",
      "{'f1_score': 0.5843077214700597, 'prec_score': 0.6012047654964056, 'rec_score': 0.5892410341951626}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.84      0.69      1766\n",
      "           1       0.53      0.65      0.59      3168\n",
      "           2       0.39      0.34      0.36      2103\n",
      "           3       0.32      0.21      0.25      1320\n",
      "           4       0.90      0.69      0.78      3633\n",
      "\n",
      "    accuracy                           0.59     11990\n",
      "   macro avg       0.54      0.55      0.53     11990\n",
      "weighted avg       0.60      0.59      0.58     11990\n",
      "[[1490  265    8    0    3]\n",
      " [ 895 2068  185    8   12]\n",
      " [ 131 1063  718  131   60]\n",
      " [  18  309  515  277  201]\n",
      " [  50  180  429  462 2512]]\n",
      "\n",
      "Train............\n",
      "{'f1_score': 0.9480950582813004, 'prec_score': 0.9494119963211043, 'rec_score': 0.9480430589260158}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95     25810\n",
      "           1       0.91      0.96      0.93     37547\n",
      "           2       0.96      0.90      0.93     20636\n",
      "           3       0.99      0.90      0.94     12182\n",
      "           4       0.98      0.97      0.98     32393\n",
      "\n",
      "    accuracy                           0.95    128568\n",
      "   macro avg       0.96      0.94      0.95    128568\n",
      "weighted avg       0.95      0.95      0.95    128568\n",
      "[[24559  1242     4     3     2]\n",
      " [ 1059 36229   203     9    47]\n",
      " [   93  1736 18644    38   125]\n",
      " [   14   403   375 10939   451]\n",
      " [  219   401   206    50 31517]]\n",
      "\n",
      "Test............\n",
      "{'f1_score': 0.6927598369285471, 'prec_score': 0.7104755005417326, 'rec_score': 0.6923462148401636}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.66      0.77      3411\n",
      "           1       0.65      0.73      0.69      3480\n",
      "           2       0.53      0.57      0.55      1657\n",
      "           3       0.43      0.38      0.41       933\n",
      "           4       0.72      0.88      0.79      2500\n",
      "\n",
      "    accuracy                           0.69     11981\n",
      "   macro avg       0.65      0.64      0.64     11981\n",
      "weighted avg       0.71      0.69      0.69     11981\n",
      "[[2257 1095   40    1   18]\n",
      " [ 118 2544  642   80   96]\n",
      " [   4  173  944  262  274]\n",
      " [   0    6  125  355  447]\n",
      " [  62   88   35  120 2195]]\n",
      "\n",
      "Train............\n",
      "{'f1_score': 0.9501700248241789, 'prec_score': 0.9514166473373257, 'rec_score': 0.9500933706816059}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95     26353\n",
      "           1       0.91      0.97      0.94     37136\n",
      "           2       0.96      0.90      0.93     20272\n",
      "           3       0.99      0.91      0.95     12003\n",
      "           4       0.98      0.97      0.98     32756\n",
      "\n",
      "    accuracy                           0.95    128520\n",
      "   macro avg       0.96      0.94      0.95    128520\n",
      "weighted avg       0.95      0.95      0.95    128520\n",
      "[[25189  1155     7     1     1]\n",
      " [ 1073 35843   187     8    25]\n",
      " [  115  1663 18341    38   115]\n",
      " [   18   391   333 10882   379]\n",
      " [  269   411   174    51 31851]]\n",
      "\n",
      "Test............\n",
      "{'f1_score': 0.7005979901605965, 'prec_score': 0.7053906274560818, 'rec_score': 0.7077895086873389}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.78      0.82      2868\n",
      "           1       0.75      0.74      0.75      3891\n",
      "           2       0.60      0.50      0.55      2021\n",
      "           3       0.42      0.32      0.36      1112\n",
      "           4       0.66      0.94      0.78      2137\n",
      "\n",
      "    accuracy                           0.71     12029\n",
      "   macro avg       0.66      0.66      0.65     12029\n",
      "weighted avg       0.71      0.71      0.70     12029\n",
      "[[2251  567   16    9   25]\n",
      " [ 338 2890  482   70  111]\n",
      " [   3  364 1019  323  312]\n",
      " [   0   22  164  352  574]\n",
      " [   7   16   26   86 2002]]\n",
      "\n",
      "Train............\n",
      "{'f1_score': 0.9480289381506176, 'prec_score': 0.9493430007667338, 'rec_score': 0.9479529127304571}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95     27284\n",
      "           1       0.91      0.96      0.93     37695\n",
      "           2       0.96      0.90      0.93     20204\n",
      "           3       0.99      0.90      0.94     11808\n",
      "           4       0.99      0.97      0.98     32046\n",
      "\n",
      "    accuracy                           0.95    129037\n",
      "   macro avg       0.96      0.94      0.95    129037\n",
      "weighted avg       0.95      0.95      0.95    129037\n",
      "[[26138  1137     4     4     1]\n",
      " [ 1165 36299   202     5    24]\n",
      " [  125  1715 18233    46    85]\n",
      " [   21   454   381 10602   350]\n",
      " [  288   448   212    49 31049]]\n",
      "\n",
      "Test............\n",
      "{'f1_score': 0.6078425378335395, 'prec_score': 0.6030093269157161, 'rec_score': 0.6217859624739402}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.81      0.72      1937\n",
      "           1       0.60      0.66      0.63      3332\n",
      "           2       0.46      0.36      0.40      2089\n",
      "           3       0.37      0.24      0.29      1307\n",
      "           4       0.79      0.82      0.80      2847\n",
      "\n",
      "    accuracy                           0.62     11512\n",
      "   macro avg       0.57      0.58      0.57     11512\n",
      "weighted avg       0.60      0.62      0.61     11512\n",
      "[[1563  356    7    0   11]\n",
      " [ 772 2200  296   35   29]\n",
      " [  39  859  751  283  157]\n",
      " [   5  169  379  313  441]\n",
      " [   8   96  187  225 2331]]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train............\n",
      "{'f1_score': 0.9509933996903205, 'prec_score': 0.9521726830294627, 'rec_score': 0.9509122299472726}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95     26608\n",
      "           1       0.91      0.97      0.94     37395\n",
      "           2       0.96      0.91      0.93     20536\n",
      "           3       0.99      0.91      0.95     12172\n",
      "           4       0.98      0.97      0.98     31875\n",
      "\n",
      "    accuracy                           0.95    128586\n",
      "   macro avg       0.96      0.94      0.95    128586\n",
      "weighted avg       0.95      0.95      0.95    128586\n",
      "[[25463  1133     9     2     1]\n",
      " [ 1054 36113   188     8    32]\n",
      " [  113  1636 18639    35   113]\n",
      " [   16   375   342 11084   355]\n",
      " [  268   412   171    49 30975]]\n",
      "\n",
      "Test............\n",
      "{'f1_score': 0.7146786640520566, 'prec_score': 0.714258290900345, 'rec_score': 0.7161247178801304}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.78      0.80      2613\n",
      "           1       0.71      0.76      0.73      3632\n",
      "           2       0.54      0.54      0.54      1757\n",
      "           3       0.39      0.35      0.37       943\n",
      "           4       0.84      0.82      0.83      3018\n",
      "\n",
      "    accuracy                           0.72     11963\n",
      "   macro avg       0.66      0.65      0.65     11963\n",
      "weighted avg       0.71      0.72      0.71     11963\n",
      "[[2049  550    8    2    4]\n",
      " [ 408 2771  372   33   48]\n",
      " [  23  447  943  186  158]\n",
      " [   6   72  263  327  275]\n",
      " [  35   77  146  283 2477]]\n",
      "\n",
      "Train............\n",
      "{'f1_score': 0.9493590608870279, 'prec_score': 0.9505897130911148, 'rec_score': 0.949282281792704}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95     26293\n",
      "           1       0.91      0.96      0.94     37536\n",
      "           2       0.96      0.90      0.93     20426\n",
      "           3       0.99      0.91      0.95     12015\n",
      "           4       0.98      0.97      0.98     32541\n",
      "\n",
      "    accuracy                           0.95    128811\n",
      "   macro avg       0.96      0.94      0.95    128811\n",
      "weighted avg       0.95      0.95      0.95    128811\n",
      "[[25066  1221     3     1     2]\n",
      " [ 1099 36202   189    10    36]\n",
      " [  119  1677 18470    43   117]\n",
      " [   21   374   346 10895   379]\n",
      " [  262   398   186    50 31645]]\n",
      "\n",
      "Test............\n",
      "{'f1_score': 0.6691623775077731, 'prec_score': 0.6749599715738703, 'rec_score': 0.6758391548815812}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.70      0.78      2928\n",
      "           1       0.66      0.73      0.69      3491\n",
      "           2       0.52      0.48      0.50      1867\n",
      "           3       0.39      0.28      0.33      1100\n",
      "           4       0.70      0.91      0.79      2352\n",
      "\n",
      "    accuracy                           0.68     11738\n",
      "   macro avg       0.63      0.62      0.62     11738\n",
      "weighted avg       0.67      0.68      0.67     11738\n",
      "[[2061  807   31   11   18]\n",
      " [ 254 2540  581   62   54]\n",
      " [   8  374  890  352  243]\n",
      " [   0   57  153  312  578]\n",
      " [  34   63   68   57 2130]]\n",
      "\n",
      "Train............\n",
      "{'f1_score': 0.9513652226600873, 'prec_score': 0.9525389240013137, 'rec_score': 0.9512947889699994}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95     26814\n",
      "           1       0.91      0.96      0.94     37466\n",
      "           2       0.96      0.90      0.93     20362\n",
      "           3       0.99      0.91      0.95     12036\n",
      "           4       0.99      0.97      0.98     31953\n",
      "\n",
      "    accuracy                           0.95    128631\n",
      "   macro avg       0.96      0.94      0.95    128631\n",
      "weighted avg       0.95      0.95      0.95    128631\n",
      "[[25765  1041     6     1     1]\n",
      " [ 1111 36139   173     8    35]\n",
      " [  127  1678 18420    39    98]\n",
      " [   12   404   316 10975   329]\n",
      " [  263   389   192    42 31067]]\n",
      "\n",
      "Test............\n",
      "{'f1_score': 0.6955655968460911, 'prec_score': 0.6921340913378005, 'rec_score': 0.7012082564188622}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.81      0.78      2407\n",
      "           1       0.69      0.73      0.71      3561\n",
      "           2       0.57      0.52      0.54      1931\n",
      "           3       0.41      0.32      0.36      1079\n",
      "           4       0.83      0.84      0.84      2940\n",
      "\n",
      "    accuracy                           0.70     11918\n",
      "   macro avg       0.65      0.64      0.64     11918\n",
      "weighted avg       0.69      0.70      0.70     11918\n",
      "[[1942  447    8    3    7]\n",
      " [ 578 2599  322   37   25]\n",
      " [  27  572  995  213  124]\n",
      " [   9   77  291  343  359]\n",
      " [  31   60  125  246 2478]]\n",
      "\n",
      "Train............\n",
      "{'f1_score': 0.9486006232272667, 'prec_score': 0.949821397696104, 'rec_score': 0.9485163147046242}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95     27942\n",
      "           1       0.91      0.96      0.93     37552\n",
      "           2       0.96      0.90      0.93     20167\n",
      "           3       0.99      0.90      0.94     11879\n",
      "           4       0.99      0.97      0.98     31025\n",
      "\n",
      "    accuracy                           0.95    128565\n",
      "   macro avg       0.96      0.94      0.95    128565\n",
      "weighted avg       0.95      0.95      0.95    128565\n",
      "[[26781  1154     4     1     2]\n",
      " [ 1192 36122   203     9    26]\n",
      " [  122  1703 18231    40    71]\n",
      " [   19   419   413 10710   318]\n",
      " [  222   423   235    43 30102]]\n",
      "\n",
      "Test............\n",
      "{'f1_score': 0.5790139931697171, 'prec_score': 0.6118084252514819, 'rec_score': 0.579105473965287}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.93      0.60      1279\n",
      "           1       0.55      0.59      0.57      3475\n",
      "           2       0.42      0.35      0.38      2126\n",
      "           3       0.34      0.24      0.28      1236\n",
      "           4       0.91      0.68      0.78      3868\n",
      "\n",
      "    accuracy                           0.58     11984\n",
      "   macro avg       0.53      0.56      0.52     11984\n",
      "weighted avg       0.61      0.58      0.58     11984\n",
      "[[1187   87    4    0    1]\n",
      " [1249 2064  147   11    4]\n",
      " [  84 1114  748  117   63]\n",
      " [  12  231  515  297  181]\n",
      " [ 175  247  363  439 2644]]\n",
      "\n",
      "Train............\n",
      "{'f1_score': 0.9485652144849768, 'prec_score': 0.9499165567349545, 'rec_score': 0.9484827537999114}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95     26944\n",
      "           1       0.91      0.97      0.93     37858\n",
      "           2       0.96      0.90      0.93     20545\n",
      "           3       0.99      0.90      0.95     12037\n",
      "           4       0.99      0.97      0.98     31369\n",
      "\n",
      "    accuracy                           0.95    128753\n",
      "   macro avg       0.96      0.94      0.95    128753\n",
      "weighted avg       0.95      0.95      0.95    128753\n",
      "[[25807  1127     7     1     2]\n",
      " [ 1109 36538   186     7    18]\n",
      " [  116  1825 18491    37    76]\n",
      " [   23   422   395 10881   316]\n",
      " [  266   418   236    46 30403]]\n",
      "\n",
      "Test............\n",
      "{'f1_score': 0.6571789660848203, 'prec_score': 0.668593268761407, 'rec_score': 0.6581044421837912}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.82      0.77      2277\n",
      "           1       0.60      0.73      0.66      3169\n",
      "           2       0.44      0.44      0.44      1748\n",
      "           3       0.33      0.26      0.29      1078\n",
      "           4       0.91      0.71      0.80      3524\n",
      "\n",
      "    accuracy                           0.66     11796\n",
      "   macro avg       0.60      0.59      0.59     11796\n",
      "weighted avg       0.67      0.66      0.66     11796\n",
      "[[1865  392   11    1    8]\n",
      " [ 598 2329  205   16   21]\n",
      " [  56  737  776  131   48]\n",
      " [  16  202  398  278  184]\n",
      " [  47  196  361  405 2515]]\n",
      "\n",
      "Train............\n",
      "{'f1_score': 0.9495457818789143, 'prec_score': 0.95081071328183, 'rec_score': 0.9494762213775841}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95     26259\n",
      "           1       0.91      0.97      0.94     37768\n",
      "           2       0.96      0.91      0.93     20687\n",
      "           3       0.99      0.90      0.94     12179\n",
      "           4       0.98      0.97      0.98     32551\n",
      "\n",
      "    accuracy                           0.95    129444\n",
      "   macro avg       0.96      0.94      0.95    129444\n",
      "weighted avg       0.95      0.95      0.95    129444\n",
      "[[25085  1164     5     2     3]\n",
      " [ 1060 36486   182     6    34]\n",
      " [  104  1690 18743    38   112]\n",
      " [   23   399   373 10993   391]\n",
      " [  255   436   212    51 31597]]\n",
      "\n",
      "Test............\n",
      "{'f1_score': 0.6762270386908418, 'prec_score': 0.6893599736053226, 'rec_score': 0.6786132372805043}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.67      0.77      2962\n",
      "           1       0.66      0.72      0.69      3259\n",
      "           2       0.48      0.49      0.49      1606\n",
      "           3       0.37      0.31      0.33       936\n",
      "           4       0.72      0.91      0.80      2342\n",
      "\n",
      "    accuracy                           0.68     11105\n",
      "   macro avg       0.63      0.62      0.62     11105\n",
      "weighted avg       0.69      0.68      0.68     11105\n",
      "[[1992  947   17    2    4]\n",
      " [ 143 2340  590  104   82]\n",
      " [   3  243  787  287  286]\n",
      " [   0   11  189  287  449]\n",
      " [  44   22   41  105 2130]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "df=experiment('overall_rf',city,rf_model_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa782d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score_train</th>\n",
       "      <th>prec_score_train</th>\n",
       "      <th>rec_score_train</th>\n",
       "      <th>f1_score_test</th>\n",
       "      <th>prec_score_test</th>\n",
       "      <th>rec_score_test</th>\n",
       "      <th>train_dev</th>\n",
       "      <th>test_dev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.949876</td>\n",
       "      <td>0.951025</td>\n",
       "      <td>0.949812</td>\n",
       "      <td>0.585746</td>\n",
       "      <td>0.601712</td>\n",
       "      <td>0.594287</td>\n",
       "      <td>[33, 34, 35, 37, 20, 22, 23, 24, 25, 28, 30]</td>\n",
       "      <td>[18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.949620</td>\n",
       "      <td>0.950817</td>\n",
       "      <td>0.949515</td>\n",
       "      <td>0.694801</td>\n",
       "      <td>0.707975</td>\n",
       "      <td>0.692648</td>\n",
       "      <td>[33, 34, 35, 37, 18, 22, 23, 24, 25, 28, 30]</td>\n",
       "      <td>[20]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.952591</td>\n",
       "      <td>0.953603</td>\n",
       "      <td>0.952497</td>\n",
       "      <td>0.584308</td>\n",
       "      <td>0.601205</td>\n",
       "      <td>0.589241</td>\n",
       "      <td>[33, 34, 35, 37, 18, 20, 23, 24, 25, 28, 30]</td>\n",
       "      <td>[22]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.948095</td>\n",
       "      <td>0.949412</td>\n",
       "      <td>0.948043</td>\n",
       "      <td>0.692760</td>\n",
       "      <td>0.710476</td>\n",
       "      <td>0.692346</td>\n",
       "      <td>[33, 34, 35, 37, 18, 20, 22, 24, 25, 28, 30]</td>\n",
       "      <td>[23]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.950170</td>\n",
       "      <td>0.951417</td>\n",
       "      <td>0.950093</td>\n",
       "      <td>0.700598</td>\n",
       "      <td>0.705391</td>\n",
       "      <td>0.707790</td>\n",
       "      <td>[33, 34, 35, 37, 18, 20, 22, 23, 25, 28, 30]</td>\n",
       "      <td>[24]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.948029</td>\n",
       "      <td>0.949343</td>\n",
       "      <td>0.947953</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.603009</td>\n",
       "      <td>0.621786</td>\n",
       "      <td>[33, 34, 35, 37, 18, 20, 22, 23, 24, 28, 30]</td>\n",
       "      <td>[25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.950993</td>\n",
       "      <td>0.952173</td>\n",
       "      <td>0.950912</td>\n",
       "      <td>0.714679</td>\n",
       "      <td>0.714258</td>\n",
       "      <td>0.716125</td>\n",
       "      <td>[33, 34, 35, 37, 18, 20, 22, 23, 24, 25, 30]</td>\n",
       "      <td>[28]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.949359</td>\n",
       "      <td>0.950590</td>\n",
       "      <td>0.949282</td>\n",
       "      <td>0.669162</td>\n",
       "      <td>0.674960</td>\n",
       "      <td>0.675839</td>\n",
       "      <td>[33, 34, 35, 37, 18, 20, 22, 23, 24, 25, 28]</td>\n",
       "      <td>[30]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.951365</td>\n",
       "      <td>0.952539</td>\n",
       "      <td>0.951295</td>\n",
       "      <td>0.695566</td>\n",
       "      <td>0.692134</td>\n",
       "      <td>0.701208</td>\n",
       "      <td>[34, 35, 37, 18, 20, 22, 23, 24, 25, 28, 30]</td>\n",
       "      <td>[33]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.948601</td>\n",
       "      <td>0.949821</td>\n",
       "      <td>0.948516</td>\n",
       "      <td>0.579014</td>\n",
       "      <td>0.611808</td>\n",
       "      <td>0.579105</td>\n",
       "      <td>[33, 35, 37, 18, 20, 22, 23, 24, 25, 28, 30]</td>\n",
       "      <td>[34]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.948565</td>\n",
       "      <td>0.949917</td>\n",
       "      <td>0.948483</td>\n",
       "      <td>0.657179</td>\n",
       "      <td>0.668593</td>\n",
       "      <td>0.658104</td>\n",
       "      <td>[33, 34, 37, 18, 20, 22, 23, 24, 25, 28, 30]</td>\n",
       "      <td>[35]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.949546</td>\n",
       "      <td>0.950811</td>\n",
       "      <td>0.949476</td>\n",
       "      <td>0.676227</td>\n",
       "      <td>0.689360</td>\n",
       "      <td>0.678613</td>\n",
       "      <td>[33, 34, 35, 18, 20, 22, 23, 24, 25, 28, 30]</td>\n",
       "      <td>[37]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    f1_score_train  prec_score_train  rec_score_train  f1_score_test  \\\n",
       "0         0.949876          0.951025         0.949812       0.585746   \n",
       "1         0.949620          0.950817         0.949515       0.694801   \n",
       "2         0.952591          0.953603         0.952497       0.584308   \n",
       "3         0.948095          0.949412         0.948043       0.692760   \n",
       "4         0.950170          0.951417         0.950093       0.700598   \n",
       "5         0.948029          0.949343         0.947953       0.607843   \n",
       "6         0.950993          0.952173         0.950912       0.714679   \n",
       "7         0.949359          0.950590         0.949282       0.669162   \n",
       "8         0.951365          0.952539         0.951295       0.695566   \n",
       "9         0.948601          0.949821         0.948516       0.579014   \n",
       "10        0.948565          0.949917         0.948483       0.657179   \n",
       "11        0.949546          0.950811         0.949476       0.676227   \n",
       "\n",
       "    prec_score_test  rec_score_test  \\\n",
       "0          0.601712        0.594287   \n",
       "1          0.707975        0.692648   \n",
       "2          0.601205        0.589241   \n",
       "3          0.710476        0.692346   \n",
       "4          0.705391        0.707790   \n",
       "5          0.603009        0.621786   \n",
       "6          0.714258        0.716125   \n",
       "7          0.674960        0.675839   \n",
       "8          0.692134        0.701208   \n",
       "9          0.611808        0.579105   \n",
       "10         0.668593        0.658104   \n",
       "11         0.689360        0.678613   \n",
       "\n",
       "                                       train_dev test_dev  \n",
       "0   [33, 34, 35, 37, 20, 22, 23, 24, 25, 28, 30]     [18]  \n",
       "1   [33, 34, 35, 37, 18, 22, 23, 24, 25, 28, 30]     [20]  \n",
       "2   [33, 34, 35, 37, 18, 20, 23, 24, 25, 28, 30]     [22]  \n",
       "3   [33, 34, 35, 37, 18, 20, 22, 24, 25, 28, 30]     [23]  \n",
       "4   [33, 34, 35, 37, 18, 20, 22, 23, 25, 28, 30]     [24]  \n",
       "5   [33, 34, 35, 37, 18, 20, 22, 23, 24, 28, 30]     [25]  \n",
       "6   [33, 34, 35, 37, 18, 20, 22, 23, 24, 25, 30]     [28]  \n",
       "7   [33, 34, 35, 37, 18, 20, 22, 23, 24, 25, 28]     [30]  \n",
       "8   [34, 35, 37, 18, 20, 22, 23, 24, 25, 28, 30]     [33]  \n",
       "9   [33, 35, 37, 18, 20, 22, 23, 24, 25, 28, 30]     [34]  \n",
       "10  [33, 34, 37, 18, 20, 22, 23, 24, 25, 28, 30]     [35]  \n",
       "11  [33, 34, 35, 18, 20, 22, 23, 24, 25, 28, 30]     [37]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd053d8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#RNN\n",
    "df=experiment('overall_rnn',city,rnn_model_fn,epochs=epochs,batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e32456c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdcfa9b",
   "metadata": {},
   "source": [
    "## Similarity based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0bec4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train............\n",
      "{'f1_score': 0.9999148077819866, 'prec_score': 0.999914835697176, 'rec_score': 0.999914806611007}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2928\n",
      "           1       1.00      1.00      1.00      3491\n",
      "           2       1.00      1.00      1.00      1867\n",
      "           3       1.00      1.00      1.00      1100\n",
      "           4       1.00      1.00      1.00      2352\n",
      "\n",
      "    accuracy                           1.00     11738\n",
      "   macro avg       1.00      1.00      1.00     11738\n",
      "weighted avg       1.00      1.00      1.00     11738\n",
      "[[2928    0    0    0    0]\n",
      " [   1 3490    0    0    0]\n",
      " [   0    0 1867    0    0]\n",
      " [   0    0    0 1100    0]\n",
      " [   0    0    0    0 2352]]\n",
      "\n",
      "Test............\n",
      "{'f1_score': 0.5458810046105055, 'prec_score': 0.5822723473019723, 'rec_score': 0.5468349625130493}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.87      0.62      1450\n",
      "           1       0.47      0.56      0.51      2787\n",
      "           2       0.38      0.29      0.33      1937\n",
      "           3       0.34      0.25      0.29      1128\n",
      "           4       0.93      0.65      0.77      3235\n",
      "\n",
      "    accuracy                           0.55     10537\n",
      "   macro avg       0.52      0.52      0.50     10537\n",
      "weighted avg       0.58      0.55      0.55     10537\n",
      "[[1255  180    4    0   11]\n",
      " [1094 1566   91    5   31]\n",
      " [ 124 1165  565   59   24]\n",
      " [  15  225  527  280   81]\n",
      " [ 133  230  290  486 2096]]\n",
      "\n",
      "Train............\n",
      "{'f1_score': 0.9996662130637665, 'prec_score': 0.9996666053924156, 'rec_score': 0.9996662216288384}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1279\n",
      "           1       1.00      1.00      1.00      3475\n",
      "           2       1.00      1.00      1.00      2126\n",
      "           3       1.00      1.00      1.00      1236\n",
      "           4       1.00      1.00      1.00      3868\n",
      "\n",
      "    accuracy                           1.00     11984\n",
      "   macro avg       1.00      1.00      1.00     11984\n",
      "weighted avg       1.00      1.00      1.00     11984\n",
      "[[1277    2    0    0    0]\n",
      " [   0 3475    0    0    0]\n",
      " [   0    2 2124    0    0]\n",
      " [   0    0    0 1236    0]\n",
      " [   0    0    0    0 3868]]\n",
      "\n",
      "Test............\n",
      "{'f1_score': 0.46981190662357064, 'prec_score': 0.5602986341129343, 'rec_score': 0.477242414138046}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.32      0.48      3323\n",
      "           1       0.48      0.48      0.48      3782\n",
      "           2       0.22      0.29      0.25      1451\n",
      "           3       0.18      0.20      0.19       943\n",
      "           4       0.55      0.90      0.68      2497\n",
      "\n",
      "    accuracy                           0.48     11996\n",
      "   macro avg       0.47      0.44      0.42     11996\n",
      "weighted avg       0.56      0.48      0.47     11996\n",
      "[[1069 1780  202   36  236]\n",
      " [  90 1799 1132  343  418]\n",
      " [   2  121  427  353  548]\n",
      " [   1   16   93  193  640]\n",
      " [   5   26  103  126 2237]]\n",
      "\n",
      "Train............\n",
      "{'f1_score': 0.9999148077819866, 'prec_score': 0.999914835697176, 'rec_score': 0.999914806611007}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2928\n",
      "           1       1.00      1.00      1.00      3491\n",
      "           2       1.00      1.00      1.00      1867\n",
      "           3       1.00      1.00      1.00      1100\n",
      "           4       1.00      1.00      1.00      2352\n",
      "\n",
      "    accuracy                           1.00     11738\n",
      "   macro avg       1.00      1.00      1.00     11738\n",
      "weighted avg       1.00      1.00      1.00     11738\n",
      "[[2928    0    0    0    0]\n",
      " [   1 3490    0    0    0]\n",
      " [   0    0 1867    0    0]\n",
      " [   0    0    0 1100    0]\n",
      " [   0    0    0    0 2352]]\n",
      "\n",
      "Test............\n",
      "{'f1_score': 0.5187503112333932, 'prec_score': 0.5505252000813691, 'rec_score': 0.5229357798165137}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.86      0.63      1766\n",
      "           1       0.47      0.56      0.51      3168\n",
      "           2       0.32      0.26      0.29      2103\n",
      "           3       0.22      0.16      0.19      1320\n",
      "           4       0.90      0.61      0.73      3633\n",
      "\n",
      "    accuracy                           0.52     11990\n",
      "   macro avg       0.48      0.49      0.47     11990\n",
      "weighted avg       0.55      0.52      0.52     11990\n",
      "[[1521  213   15    1   16]\n",
      " [1227 1763  122   16   40]\n",
      " [ 223 1169  551  109   51]\n",
      " [  51  393  529  214  133]\n",
      " [  59  246  487  620 2221]]\n",
      "\n",
      "Train............\n",
      "{'f1_score': 1.0, 'prec_score': 1.0, 'rec_score': 1.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1766\n",
      "           1       1.00      1.00      1.00      3168\n",
      "           2       1.00      1.00      1.00      2103\n",
      "           3       1.00      1.00      1.00      1320\n",
      "           4       1.00      1.00      1.00      3633\n",
      "\n",
      "    accuracy                           1.00     11990\n",
      "   macro avg       1.00      1.00      1.00     11990\n",
      "weighted avg       1.00      1.00      1.00     11990\n",
      "[[1766    0    0    0    0]\n",
      " [   0 3168    0    0    0]\n",
      " [   0    0 2103    0    0]\n",
      " [   0    0    0 1320    0]\n",
      " [   0    0    0    0 3633]]\n",
      "\n",
      "Test............\n",
      "{'f1_score': 0.4985114799422929, 'prec_score': 0.5589737933848725, 'rec_score': 0.500375594691595}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.44      0.59      3411\n",
      "           1       0.48      0.46      0.47      3480\n",
      "           2       0.26      0.29      0.28      1657\n",
      "           3       0.18      0.21      0.19       933\n",
      "           4       0.54      0.88      0.67      2500\n",
      "\n",
      "    accuracy                           0.50     11981\n",
      "   macro avg       0.47      0.46      0.44     11981\n",
      "weighted avg       0.56      0.50      0.50     11981\n",
      "[[1502 1472  248   42  147]\n",
      " [ 113 1610  957  331  469]\n",
      " [  11  149  480  393  624]\n",
      " [   0   16   86  193  638]\n",
      " [  45  108   42   95 2210]]\n",
      "\n",
      "Train............\n",
      "{'f1_score': 0.9999160904774149, 'prec_score': 0.9999161168603085, 'rec_score': 0.9999160933042457}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2407\n",
      "           1       1.00      1.00      1.00      3561\n",
      "           2       1.00      1.00      1.00      1931\n",
      "           3       1.00      1.00      1.00      1079\n",
      "           4       1.00      1.00      1.00      2940\n",
      "\n",
      "    accuracy                           1.00     11918\n",
      "   macro avg       1.00      1.00      1.00     11918\n",
      "weighted avg       1.00      1.00      1.00     11918\n",
      "[[2406    1    0    0    0]\n",
      " [   0 3561    0    0    0]\n",
      " [   0    0 1931    0    0]\n",
      " [   0    0    0 1079    0]\n",
      " [   0    0    0    0 2940]]\n",
      "\n",
      "Test............\n",
      "{'f1_score': 0.6241476567993235, 'prec_score': 0.6343847334440612, 'rec_score': 0.6325546595726993}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.65      0.72      2868\n",
      "           1       0.66      0.67      0.66      3891\n",
      "           2       0.51      0.45      0.48      2021\n",
      "           3       0.32      0.24      0.27      1112\n",
      "           4       0.61      0.93      0.74      2137\n",
      "\n",
      "    accuracy                           0.63     12029\n",
      "   macro avg       0.59      0.59      0.58     12029\n",
      "weighted avg       0.63      0.63      0.62     12029\n",
      "[[1851  915   37   16   49]\n",
      " [ 363 2590  668  110  160]\n",
      " [  17  375  913  346  370]\n",
      " [   3   39  134  264  672]\n",
      " [   8   22   23   93 1991]]\n",
      "\n",
      "Train............\n",
      "{'f1_score': 0.9999160904774149, 'prec_score': 0.9999161168603085, 'rec_score': 0.9999160933042457}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2407\n",
      "           1       1.00      1.00      1.00      3561\n",
      "           2       1.00      1.00      1.00      1931\n",
      "           3       1.00      1.00      1.00      1079\n",
      "           4       1.00      1.00      1.00      2940\n",
      "\n",
      "    accuracy                           1.00     11918\n",
      "   macro avg       1.00      1.00      1.00     11918\n",
      "weighted avg       1.00      1.00      1.00     11918\n",
      "[[2406    1    0    0    0]\n",
      " [   0 3561    0    0    0]\n",
      " [   0    0 1931    0    0]\n",
      " [   0    0    0 1079    0]\n",
      " [   0    0    0    0 2940]]\n",
      "\n",
      "Test............\n",
      "{'f1_score': 0.5961505325625175, 'prec_score': 0.5893589141390999, 'rec_score': 0.6100590687977763}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.75      0.70      1937\n",
      "           1       0.60      0.66      0.63      3332\n",
      "           2       0.44      0.37      0.40      2089\n",
      "           3       0.34      0.21      0.26      1307\n",
      "           4       0.75      0.82      0.78      2847\n",
      "\n",
      "    accuracy                           0.61     11512\n",
      "   macro avg       0.56      0.56      0.56     11512\n",
      "weighted avg       0.59      0.61      0.60     11512\n",
      "[[1446  441   27    1   22]\n",
      " [ 669 2204  343   49   67]\n",
      " [  52  790  765  246  236]\n",
      " [  11  159  400  279  458]\n",
      " [   8   73  195  242 2329]]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train............\n",
      "{'f1_score': 0.999715300169235, 'prec_score': 0.9997155951225635, 'rec_score': 0.9997152889816836}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1450\n",
      "           1       1.00      1.00      1.00      2787\n",
      "           2       1.00      1.00      1.00      1937\n",
      "           3       1.00      1.00      1.00      1128\n",
      "           4       1.00      1.00      1.00      3235\n",
      "\n",
      "    accuracy                           1.00     10537\n",
      "   macro avg       1.00      1.00      1.00     10537\n",
      "weighted avg       1.00      1.00      1.00     10537\n",
      "[[1449    1    0    0    0]\n",
      " [   0 2787    0    0    0]\n",
      " [   0    2 1935    0    0]\n",
      " [   0    0    0 1128    0]\n",
      " [   0    0    0    0 3235]]\n",
      "\n",
      "Test............\n",
      "{'f1_score': 0.5580329026400455, 'prec_score': 0.5718344307277062, 'rec_score': 0.5621499623840174}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.48      0.59      2613\n",
      "           1       0.54      0.56      0.55      3632\n",
      "           2       0.34      0.36      0.35      1757\n",
      "           3       0.27      0.26      0.26       943\n",
      "           4       0.68      0.85      0.76      3018\n",
      "\n",
      "    accuracy                           0.56     11963\n",
      "   macro avg       0.52      0.50      0.50     11963\n",
      "weighted avg       0.57      0.56      0.56     11963\n",
      "[[1259 1122   97   12  123]\n",
      " [ 328 2021  861  149  273]\n",
      " [  41  404  638  294  380]\n",
      " [  11   85  173  246  428]\n",
      " [  32   88  122  215 2561]]\n",
      "\n",
      "Train............\n",
      "{'f1_score': 0.999715300169235, 'prec_score': 0.9997155951225635, 'rec_score': 0.9997152889816836}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1450\n",
      "           1       1.00      1.00      1.00      2787\n",
      "           2       1.00      1.00      1.00      1937\n",
      "           3       1.00      1.00      1.00      1128\n",
      "           4       1.00      1.00      1.00      3235\n",
      "\n",
      "    accuracy                           1.00     10537\n",
      "   macro avg       1.00      1.00      1.00     10537\n",
      "weighted avg       1.00      1.00      1.00     10537\n",
      "[[1449    1    0    0    0]\n",
      " [   0 2787    0    0    0]\n",
      " [   0    2 1935    0    0]\n",
      " [   0    0    0 1128    0]\n",
      " [   0    0    0    0 3235]]\n",
      "\n",
      "Test............\n",
      "{'f1_score': 0.516969096337049, 'prec_score': 0.5557548925648554, 'rec_score': 0.5257284034758902}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.45      0.58      2928\n",
      "           1       0.52      0.51      0.51      3491\n",
      "           2       0.34      0.35      0.34      1867\n",
      "           3       0.26      0.24      0.25      1100\n",
      "           4       0.57      0.93      0.71      2352\n",
      "\n",
      "    accuracy                           0.53     11738\n",
      "   macro avg       0.51      0.49      0.48     11738\n",
      "weighted avg       0.56      0.53      0.52     11738\n",
      "[[1306 1343   77    8  194]\n",
      " [ 186 1769 1094  140  302]\n",
      " [  32  227  656  512  440]\n",
      " [   9   37   86  259  709]\n",
      " [  20   50   40   61 2181]]\n",
      "\n",
      "Train............\n",
      "{'f1_score': 0.9999148077819866, 'prec_score': 0.999914835697176, 'rec_score': 0.999914806611007}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2928\n",
      "           1       1.00      1.00      1.00      3491\n",
      "           2       1.00      1.00      1.00      1867\n",
      "           3       1.00      1.00      1.00      1100\n",
      "           4       1.00      1.00      1.00      2352\n",
      "\n",
      "    accuracy                           1.00     11738\n",
      "   macro avg       1.00      1.00      1.00     11738\n",
      "weighted avg       1.00      1.00      1.00     11738\n",
      "[[2928    0    0    0    0]\n",
      " [   1 3490    0    0    0]\n",
      " [   0    0 1867    0    0]\n",
      " [   0    0    0 1100    0]\n",
      " [   0    0    0    0 2352]]\n",
      "\n",
      "Test............\n",
      "{'f1_score': 0.6406330892519546, 'prec_score': 0.6485797726168151, 'rec_score': 0.641047155563014}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.78      0.71      2407\n",
      "           1       0.62      0.67      0.64      3561\n",
      "           2       0.50      0.45      0.47      1931\n",
      "           3       0.35      0.31      0.33      1079\n",
      "           4       0.90      0.73      0.81      2940\n",
      "\n",
      "    accuracy                           0.64     11918\n",
      "   macro avg       0.60      0.59      0.59     11918\n",
      "weighted avg       0.65      0.64      0.64     11918\n",
      "[[1885  471   23    4   24]\n",
      " [ 874 2396  218   27   46]\n",
      " [  91  805  876  113   46]\n",
      " [  24  134  468  333  120]\n",
      " [  52   81  181  476 2150]]\n",
      "\n",
      "Train............\n",
      "{'f1_score': 1.0, 'prec_score': 1.0, 'rec_score': 1.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2277\n",
      "           1       1.00      1.00      1.00      3169\n",
      "           2       1.00      1.00      1.00      1748\n",
      "           3       1.00      1.00      1.00      1078\n",
      "           4       1.00      1.00      1.00      3524\n",
      "\n",
      "    accuracy                           1.00     11796\n",
      "   macro avg       1.00      1.00      1.00     11796\n",
      "weighted avg       1.00      1.00      1.00     11796\n",
      "[[2277    0    0    0    0]\n",
      " [   0 3169    0    0    0]\n",
      " [   0    0 1748    0    0]\n",
      " [   0    0    0 1078    0]\n",
      " [   0    0    0    0 3524]]\n",
      "\n",
      "Test............\n",
      "{'f1_score': 0.6245973151274306, 'prec_score': 0.6360271627999413, 'rec_score': 0.632343124165554}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.86      0.61      1279\n",
      "           1       0.63      0.61      0.62      3475\n",
      "           2       0.55      0.40      0.47      2126\n",
      "           3       0.41      0.28      0.33      1236\n",
      "           4       0.82      0.81      0.81      3868\n",
      "\n",
      "    accuracy                           0.63     11984\n",
      "   macro avg       0.57      0.59      0.57     11984\n",
      "weighted avg       0.64      0.63      0.62     11984\n",
      "[[1103  159    4    1   12]\n",
      " [1011 2130  211   32   91]\n",
      " [  74  782  859  187  224]\n",
      " [  18  141  353  340  384]\n",
      " [ 157  150  141  274 3146]]\n",
      "\n",
      "Train............\n",
      "{'f1_score': 0.9996662130637665, 'prec_score': 0.9996666053924156, 'rec_score': 0.9996662216288384}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1279\n",
      "           1       1.00      1.00      1.00      3475\n",
      "           2       1.00      1.00      1.00      2126\n",
      "           3       1.00      1.00      1.00      1236\n",
      "           4       1.00      1.00      1.00      3868\n",
      "\n",
      "    accuracy                           1.00     11984\n",
      "   macro avg       1.00      1.00      1.00     11984\n",
      "weighted avg       1.00      1.00      1.00     11984\n",
      "[[1277    2    0    0    0]\n",
      " [   0 3475    0    0    0]\n",
      " [   0    2 2124    0    0]\n",
      " [   0    0    0 1236    0]\n",
      " [   0    0    0    0 3868]]\n",
      "\n",
      "Test............\n",
      "{'f1_score': 0.6348463005915278, 'prec_score': 0.663631356797864, 'rec_score': 0.6418277382163445}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.42      0.57      2277\n",
      "           1       0.59      0.71      0.64      3169\n",
      "           2       0.48      0.51      0.50      1748\n",
      "           3       0.36      0.34      0.35      1078\n",
      "           4       0.78      0.88      0.83      3524\n",
      "\n",
      "    accuracy                           0.64     11796\n",
      "   macro avg       0.62      0.57      0.58     11796\n",
      "weighted avg       0.66      0.64      0.63     11796\n",
      "[[ 957 1136   42    1  141]\n",
      " [ 115 2263  604   73  114]\n",
      " [   4  333  899  335  177]\n",
      " [   0   66  213  368  431]\n",
      " [  20   64  103  253 3084]]\n",
      "\n",
      "Train............\n",
      "{'f1_score': 0.999715300169235, 'prec_score': 0.9997155951225635, 'rec_score': 0.9997152889816836}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1450\n",
      "           1       1.00      1.00      1.00      2787\n",
      "           2       1.00      1.00      1.00      1937\n",
      "           3       1.00      1.00      1.00      1128\n",
      "           4       1.00      1.00      1.00      3235\n",
      "\n",
      "    accuracy                           1.00     10537\n",
      "   macro avg       1.00      1.00      1.00     10537\n",
      "weighted avg       1.00      1.00      1.00     10537\n",
      "[[1449    1    0    0    0]\n",
      " [   0 2787    0    0    0]\n",
      " [   0    2 1935    0    0]\n",
      " [   0    0    0 1128    0]\n",
      " [   0    0    0    0 3235]]\n",
      "\n",
      "Test............\n",
      "{'f1_score': 0.5221613117856861, 'prec_score': 0.5628155001318329, 'rec_score': 0.5271499324628546}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.44      0.58      2962\n",
      "           1       0.48      0.51      0.50      3259\n",
      "           2       0.30      0.34      0.32      1606\n",
      "           3       0.26      0.24      0.25       936\n",
      "           4       0.62      0.90      0.74      2342\n",
      "\n",
      "    accuracy                           0.53     11105\n",
      "   macro avg       0.50      0.49      0.48     11105\n",
      "weighted avg       0.56      0.53      0.52     11105\n",
      "[[1300 1450  118    7   87]\n",
      " [ 168 1673  995  191  232]\n",
      " [  26  282  548  336  414]\n",
      " [   1   35  133  222  545]\n",
      " [  45   23   51  112 2111]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "df=experiment('sim_rf',city,rf_model_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1793e719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score_train</th>\n",
       "      <th>prec_score_train</th>\n",
       "      <th>rec_score_train</th>\n",
       "      <th>f1_score_test</th>\n",
       "      <th>prec_score_test</th>\n",
       "      <th>rec_score_test</th>\n",
       "      <th>train_dev</th>\n",
       "      <th>test_dev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.545881</td>\n",
       "      <td>0.582272</td>\n",
       "      <td>0.546835</td>\n",
       "      <td>[30]</td>\n",
       "      <td>[18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999666</td>\n",
       "      <td>0.999667</td>\n",
       "      <td>0.999666</td>\n",
       "      <td>0.469812</td>\n",
       "      <td>0.560299</td>\n",
       "      <td>0.477242</td>\n",
       "      <td>[34]</td>\n",
       "      <td>[20]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.518750</td>\n",
       "      <td>0.550525</td>\n",
       "      <td>0.522936</td>\n",
       "      <td>[30]</td>\n",
       "      <td>[22]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.498511</td>\n",
       "      <td>0.558974</td>\n",
       "      <td>0.500376</td>\n",
       "      <td>[22]</td>\n",
       "      <td>[23]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.999916</td>\n",
       "      <td>0.999916</td>\n",
       "      <td>0.999916</td>\n",
       "      <td>0.624148</td>\n",
       "      <td>0.634385</td>\n",
       "      <td>0.632555</td>\n",
       "      <td>[33]</td>\n",
       "      <td>[24]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.999916</td>\n",
       "      <td>0.999916</td>\n",
       "      <td>0.999916</td>\n",
       "      <td>0.596151</td>\n",
       "      <td>0.589359</td>\n",
       "      <td>0.610059</td>\n",
       "      <td>[33]</td>\n",
       "      <td>[25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.999715</td>\n",
       "      <td>0.999716</td>\n",
       "      <td>0.999715</td>\n",
       "      <td>0.558033</td>\n",
       "      <td>0.571834</td>\n",
       "      <td>0.562150</td>\n",
       "      <td>[18]</td>\n",
       "      <td>[28]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.999715</td>\n",
       "      <td>0.999716</td>\n",
       "      <td>0.999715</td>\n",
       "      <td>0.516969</td>\n",
       "      <td>0.555755</td>\n",
       "      <td>0.525728</td>\n",
       "      <td>[18]</td>\n",
       "      <td>[30]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.640633</td>\n",
       "      <td>0.648580</td>\n",
       "      <td>0.641047</td>\n",
       "      <td>[30]</td>\n",
       "      <td>[33]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.624597</td>\n",
       "      <td>0.636027</td>\n",
       "      <td>0.632343</td>\n",
       "      <td>[35]</td>\n",
       "      <td>[34]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.999666</td>\n",
       "      <td>0.999667</td>\n",
       "      <td>0.999666</td>\n",
       "      <td>0.634846</td>\n",
       "      <td>0.663631</td>\n",
       "      <td>0.641828</td>\n",
       "      <td>[34]</td>\n",
       "      <td>[35]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.999715</td>\n",
       "      <td>0.999716</td>\n",
       "      <td>0.999715</td>\n",
       "      <td>0.522161</td>\n",
       "      <td>0.562816</td>\n",
       "      <td>0.527150</td>\n",
       "      <td>[18]</td>\n",
       "      <td>[37]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    f1_score_train  prec_score_train  rec_score_train  f1_score_test  \\\n",
       "0         0.999915          0.999915         0.999915       0.545881   \n",
       "1         0.999666          0.999667         0.999666       0.469812   \n",
       "2         0.999915          0.999915         0.999915       0.518750   \n",
       "3         1.000000          1.000000         1.000000       0.498511   \n",
       "4         0.999916          0.999916         0.999916       0.624148   \n",
       "5         0.999916          0.999916         0.999916       0.596151   \n",
       "6         0.999715          0.999716         0.999715       0.558033   \n",
       "7         0.999715          0.999716         0.999715       0.516969   \n",
       "8         0.999915          0.999915         0.999915       0.640633   \n",
       "9         1.000000          1.000000         1.000000       0.624597   \n",
       "10        0.999666          0.999667         0.999666       0.634846   \n",
       "11        0.999715          0.999716         0.999715       0.522161   \n",
       "\n",
       "    prec_score_test  rec_score_test train_dev test_dev  \n",
       "0          0.582272        0.546835      [30]     [18]  \n",
       "1          0.560299        0.477242      [34]     [20]  \n",
       "2          0.550525        0.522936      [30]     [22]  \n",
       "3          0.558974        0.500376      [22]     [23]  \n",
       "4          0.634385        0.632555      [33]     [24]  \n",
       "5          0.589359        0.610059      [33]     [25]  \n",
       "6          0.571834        0.562150      [18]     [28]  \n",
       "7          0.555755        0.525728      [18]     [30]  \n",
       "8          0.648580        0.641047      [30]     [33]  \n",
       "9          0.636027        0.632343      [35]     [34]  \n",
       "10         0.663631        0.641828      [34]     [35]  \n",
       "11         0.562816        0.527150      [18]     [37]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72f188d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RNN\n",
    "df=experiment('sim_rnn',city,rnn_model_fn,epochs=epochs,batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c34435d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb4567e",
   "metadata": {},
   "source": [
    "## Distance based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f7288a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train............\n",
      "{'f1_score': 0.9999148077819866, 'prec_score': 0.999914835697176, 'rec_score': 0.999914806611007}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2928\n",
      "           1       1.00      1.00      1.00      3491\n",
      "           2       1.00      1.00      1.00      1867\n",
      "           3       1.00      1.00      1.00      1100\n",
      "           4       1.00      1.00      1.00      2352\n",
      "\n",
      "    accuracy                           1.00     11738\n",
      "   macro avg       1.00      1.00      1.00     11738\n",
      "weighted avg       1.00      1.00      1.00     11738\n",
      "[[2928    0    0    0    0]\n",
      " [   1 3490    0    0    0]\n",
      " [   0    0 1867    0    0]\n",
      " [   0    0    0 1100    0]\n",
      " [   0    0    0    0 2352]]\n",
      "\n",
      "Test............\n",
      "{'f1_score': 0.5458810046105055, 'prec_score': 0.5822723473019723, 'rec_score': 0.5468349625130493}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.87      0.62      1450\n",
      "           1       0.47      0.56      0.51      2787\n",
      "           2       0.38      0.29      0.33      1937\n",
      "           3       0.34      0.25      0.29      1128\n",
      "           4       0.93      0.65      0.77      3235\n",
      "\n",
      "    accuracy                           0.55     10537\n",
      "   macro avg       0.52      0.52      0.50     10537\n",
      "weighted avg       0.58      0.55      0.55     10537\n",
      "[[1255  180    4    0   11]\n",
      " [1094 1566   91    5   31]\n",
      " [ 124 1165  565   59   24]\n",
      " [  15  225  527  280   81]\n",
      " [ 133  230  290  486 2096]]\n",
      "\n",
      "Train............\n",
      "{'f1_score': 0.9997496262316782, 'prec_score': 0.9997498235709762, 'rec_score': 0.9997496035389366}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3411\n",
      "           1       1.00      1.00      1.00      3480\n",
      "           2       1.00      1.00      1.00      1657\n",
      "           3       1.00      1.00      1.00       933\n",
      "           4       1.00      1.00      1.00      2500\n",
      "\n",
      "    accuracy                           1.00     11981\n",
      "   macro avg       1.00      1.00      1.00     11981\n",
      "weighted avg       1.00      1.00      1.00     11981\n",
      "[[3411    0    0    0    0]\n",
      " [   2 3478    0    0    0]\n",
      " [   0    0 1657    0    0]\n",
      " [   0    0    0  933    0]\n",
      " [   1    0    0    0 2499]]\n",
      "\n",
      "Test............\n",
      "{'f1_score': 0.6772132937807146, 'prec_score': 0.675519657133401, 'rec_score': 0.6842280760253417}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.83      0.78      3323\n",
      "           1       0.64      0.68      0.66      3782\n",
      "           2       0.50      0.39      0.44      1451\n",
      "           3       0.50      0.37      0.43       943\n",
      "           4       0.82      0.79      0.80      2497\n",
      "\n",
      "    accuracy                           0.68     11996\n",
      "   macro avg       0.64      0.61      0.62     11996\n",
      "weighted avg       0.68      0.68      0.68     11996\n",
      "[[2758  507   17    6   35]\n",
      " [ 871 2568  241   19   83]\n",
      " [  89  582  563  166   51]\n",
      " [  25  142  160  350  266]\n",
      " [  28  193  149  158 1969]]\n",
      "\n",
      "Train............\n",
      "{'f1_score': 1.0, 'prec_score': 1.0, 'rec_score': 1.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1937\n",
      "           1       1.00      1.00      1.00      3332\n",
      "           2       1.00      1.00      1.00      2089\n",
      "           3       1.00      1.00      1.00      1307\n",
      "           4       1.00      1.00      1.00      2847\n",
      "\n",
      "    accuracy                           1.00     11512\n",
      "   macro avg       1.00      1.00      1.00     11512\n",
      "weighted avg       1.00      1.00      1.00     11512\n",
      "[[1937    0    0    0    0]\n",
      " [   0 3332    0    0    0]\n",
      " [   0    0 2089    0    0]\n",
      " [   0    0    0 1307    0]\n",
      " [   0    0    0    0 2847]]\n",
      "\n",
      "Test............\n",
      "{'f1_score': 0.5889548667889117, 'prec_score': 0.5919392859886886, 'rec_score': 0.5889908256880734}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.65      0.64      1766\n",
      "           1       0.56      0.64      0.60      3168\n",
      "           2       0.41      0.41      0.41      2103\n",
      "           3       0.30      0.26      0.28      1320\n",
      "           4       0.82      0.74      0.78      3633\n",
      "\n",
      "    accuracy                           0.59     11990\n",
      "   macro avg       0.54      0.54      0.54     11990\n",
      "weighted avg       0.59      0.59      0.59     11990\n",
      "[[1146  553   33    7   27]\n",
      " [ 566 2025  455   49   73]\n",
      " [  79  752  853  248  171]\n",
      " [   9  204  433  345  329]\n",
      " [  40  102  299  499 2693]]\n",
      "\n",
      "Train............\n",
      "{'f1_score': 0.9998337277122443, 'prec_score': 0.9998337854760004, 'rec_score': 0.9998337351400781}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2868\n",
      "           1       1.00      1.00      1.00      3891\n",
      "           2       1.00      1.00      1.00      2021\n",
      "           3       1.00      1.00      1.00      1112\n",
      "           4       1.00      1.00      1.00      2137\n",
      "\n",
      "    accuracy                           1.00     12029\n",
      "   macro avg       1.00      1.00      1.00     12029\n",
      "weighted avg       1.00      1.00      1.00     12029\n",
      "[[2868    0    0    0    0]\n",
      " [   0 3891    0    0    0]\n",
      " [   0    1 2020    0    0]\n",
      " [   0    0    0 1112    0]\n",
      " [   1    0    0    0 2136]]\n",
      "\n",
      "Test............\n",
      "{'f1_score': 0.7276668940439408, 'prec_score': 0.7487833285408857, 'rec_score': 0.7223103246807445}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.69      0.78      3411\n",
      "           1       0.66      0.79      0.72      3480\n",
      "           2       0.55      0.70      0.62      1657\n",
      "           3       0.50      0.50      0.50       933\n",
      "           4       0.89      0.78      0.83      2500\n",
      "\n",
      "    accuracy                           0.72     11981\n",
      "   macro avg       0.70      0.69      0.69     11981\n",
      "weighted avg       0.75      0.72      0.73     11981\n",
      "[[2339  979   79    8    6]\n",
      " [ 167 2745  525   19   24]\n",
      " [  15  267 1159  162   54]\n",
      " [   8   45  256  464  160]\n",
      " [  63  137   79  274 1947]]\n",
      "\n",
      "Train............\n",
      "{'f1_score': 0.9997496262316782, 'prec_score': 0.9997498235709762, 'rec_score': 0.9997496035389366}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3411\n",
      "           1       1.00      1.00      1.00      3480\n",
      "           2       1.00      1.00      1.00      1657\n",
      "           3       1.00      1.00      1.00       933\n",
      "           4       1.00      1.00      1.00      2500\n",
      "\n",
      "    accuracy                           1.00     11981\n",
      "   macro avg       1.00      1.00      1.00     11981\n",
      "weighted avg       1.00      1.00      1.00     11981\n",
      "[[3411    0    0    0    0]\n",
      " [   2 3478    0    0    0]\n",
      " [   0    0 1657    0    0]\n",
      " [   0    0    0  933    0]\n",
      " [   1    0    0    0 2499]]\n",
      "\n",
      "Test............\n",
      "{'f1_score': 0.6651324951404626, 'prec_score': 0.6803898753409693, 'rec_score': 0.6815196608196857}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.90      0.77      2868\n",
      "           1       0.66      0.66      0.66      3891\n",
      "           2       0.72      0.38      0.50      2021\n",
      "           3       0.59      0.37      0.46      1112\n",
      "           4       0.75      0.86      0.80      2137\n",
      "\n",
      "    accuracy                           0.68     12029\n",
      "   macro avg       0.68      0.64      0.64     12029\n",
      "weighted avg       0.68      0.68      0.67     12029\n",
      "[[2589  206    2    4   67]\n",
      " [1028 2583  142   19  119]\n",
      " [ 184  765  767  188  117]\n",
      " [  39  196  136  415  326]\n",
      " [  32  158   25   78 1844]]\n",
      "\n",
      "Train............\n",
      "{'f1_score': 1.0, 'prec_score': 1.0, 'rec_score': 1.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1766\n",
      "           1       1.00      1.00      1.00      3168\n",
      "           2       1.00      1.00      1.00      2103\n",
      "           3       1.00      1.00      1.00      1320\n",
      "           4       1.00      1.00      1.00      3633\n",
      "\n",
      "    accuracy                           1.00     11990\n",
      "   macro avg       1.00      1.00      1.00     11990\n",
      "weighted avg       1.00      1.00      1.00     11990\n",
      "[[1766    0    0    0    0]\n",
      " [   0 3168    0    0    0]\n",
      " [   0    0 2103    0    0]\n",
      " [   0    0    0 1320    0]\n",
      " [   0    0    0    0 3633]]\n",
      "\n",
      "Test............\n",
      "{'f1_score': 0.5651232637141619, 'prec_score': 0.5671518254995085, 'rec_score': 0.5770500347463516}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.54      0.62      1937\n",
      "           1       0.59      0.60      0.60      3332\n",
      "           2       0.41      0.37      0.39      2089\n",
      "           3       0.30      0.24      0.26      1307\n",
      "           4       0.66      0.88      0.76      2847\n",
      "\n",
      "    accuracy                           0.58     11512\n",
      "   macro avg       0.54      0.53      0.53     11512\n",
      "weighted avg       0.57      0.58      0.57     11512\n",
      "[[1040  755  100    8   34]\n",
      " [ 355 2000  662  151  164]\n",
      " [  23  489  774  381  422]\n",
      " [   3   78  249  311  666]\n",
      " [   8   41   85  195 2518]]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train............\n",
      "{'f1_score': 0.9999148077819866, 'prec_score': 0.999914835697176, 'rec_score': 0.999914806611007}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2928\n",
      "           1       1.00      1.00      1.00      3491\n",
      "           2       1.00      1.00      1.00      1867\n",
      "           3       1.00      1.00      1.00      1100\n",
      "           4       1.00      1.00      1.00      2352\n",
      "\n",
      "    accuracy                           1.00     11738\n",
      "   macro avg       1.00      1.00      1.00     11738\n",
      "weighted avg       1.00      1.00      1.00     11738\n",
      "[[2928    0    0    0    0]\n",
      " [   1 3490    0    0    0]\n",
      " [   0    0 1867    0    0]\n",
      " [   0    0    0 1100    0]\n",
      " [   0    0    0    0 2352]]\n",
      "\n",
      "Test............\n",
      "{'f1_score': 0.6342321358327377, 'prec_score': 0.6439720334382503, 'rec_score': 0.6309454150296748}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.75      0.72      2613\n",
      "           1       0.61      0.67      0.64      3632\n",
      "           2       0.43      0.43      0.43      1757\n",
      "           3       0.29      0.29      0.29       943\n",
      "           4       0.88      0.70      0.78      3018\n",
      "\n",
      "    accuracy                           0.63     11963\n",
      "   macro avg       0.58      0.57      0.57     11963\n",
      "weighted avg       0.64      0.63      0.63     11963\n",
      "[[1958  595   29    6   25]\n",
      " [ 751 2431  333   55   62]\n",
      " [  68  717  758  140   74]\n",
      " [  18  125  400  277  123]\n",
      " [  39  126  247  482 2124]]\n",
      "\n",
      "Train............\n",
      "{'f1_score': 0.999715300169235, 'prec_score': 0.9997155951225635, 'rec_score': 0.9997152889816836}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1450\n",
      "           1       1.00      1.00      1.00      2787\n",
      "           2       1.00      1.00      1.00      1937\n",
      "           3       1.00      1.00      1.00      1128\n",
      "           4       1.00      1.00      1.00      3235\n",
      "\n",
      "    accuracy                           1.00     10537\n",
      "   macro avg       1.00      1.00      1.00     10537\n",
      "weighted avg       1.00      1.00      1.00     10537\n",
      "[[1449    1    0    0    0]\n",
      " [   0 2787    0    0    0]\n",
      " [   0    2 1935    0    0]\n",
      " [   0    0    0 1128    0]\n",
      " [   0    0    0    0 3235]]\n",
      "\n",
      "Test............\n",
      "{'f1_score': 0.516969096337049, 'prec_score': 0.5557548925648554, 'rec_score': 0.5257284034758902}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.45      0.58      2928\n",
      "           1       0.52      0.51      0.51      3491\n",
      "           2       0.34      0.35      0.34      1867\n",
      "           3       0.26      0.24      0.25      1100\n",
      "           4       0.57      0.93      0.71      2352\n",
      "\n",
      "    accuracy                           0.53     11738\n",
      "   macro avg       0.51      0.49      0.48     11738\n",
      "weighted avg       0.56      0.53      0.52     11738\n",
      "[[1306 1343   77    8  194]\n",
      " [ 186 1769 1094  140  302]\n",
      " [  32  227  656  512  440]\n",
      " [   9   37   86  259  709]\n",
      " [  20   50   40   61 2181]]\n",
      "\n",
      "Train............\n",
      "{'f1_score': 0.9999148077819866, 'prec_score': 0.999914835697176, 'rec_score': 0.999914806611007}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2928\n",
      "           1       1.00      1.00      1.00      3491\n",
      "           2       1.00      1.00      1.00      1867\n",
      "           3       1.00      1.00      1.00      1100\n",
      "           4       1.00      1.00      1.00      2352\n",
      "\n",
      "    accuracy                           1.00     11738\n",
      "   macro avg       1.00      1.00      1.00     11738\n",
      "weighted avg       1.00      1.00      1.00     11738\n",
      "[[2928    0    0    0    0]\n",
      " [   1 3490    0    0    0]\n",
      " [   0    0 1867    0    0]\n",
      " [   0    0    0 1100    0]\n",
      " [   0    0    0    0 2352]]\n",
      "\n",
      "Test............\n",
      "{'f1_score': 0.6406330892519546, 'prec_score': 0.6485797726168151, 'rec_score': 0.641047155563014}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.78      0.71      2407\n",
      "           1       0.62      0.67      0.64      3561\n",
      "           2       0.50      0.45      0.47      1931\n",
      "           3       0.35      0.31      0.33      1079\n",
      "           4       0.90      0.73      0.81      2940\n",
      "\n",
      "    accuracy                           0.64     11918\n",
      "   macro avg       0.60      0.59      0.59     11918\n",
      "weighted avg       0.65      0.64      0.64     11918\n",
      "[[1885  471   23    4   24]\n",
      " [ 874 2396  218   27   46]\n",
      " [  91  805  876  113   46]\n",
      " [  24  134  468  333  120]\n",
      " [  52   81  181  476 2150]]\n",
      "\n",
      "Train............\n",
      "{'f1_score': 1.0, 'prec_score': 1.0, 'rec_score': 1.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2277\n",
      "           1       1.00      1.00      1.00      3169\n",
      "           2       1.00      1.00      1.00      1748\n",
      "           3       1.00      1.00      1.00      1078\n",
      "           4       1.00      1.00      1.00      3524\n",
      "\n",
      "    accuracy                           1.00     11796\n",
      "   macro avg       1.00      1.00      1.00     11796\n",
      "weighted avg       1.00      1.00      1.00     11796\n",
      "[[2277    0    0    0    0]\n",
      " [   0 3169    0    0    0]\n",
      " [   0    0 1748    0    0]\n",
      " [   0    0    0 1078    0]\n",
      " [   0    0    0    0 3524]]\n",
      "\n",
      "Test............\n",
      "{'f1_score': 0.6245973151274306, 'prec_score': 0.6360271627999413, 'rec_score': 0.632343124165554}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.86      0.61      1279\n",
      "           1       0.63      0.61      0.62      3475\n",
      "           2       0.55      0.40      0.47      2126\n",
      "           3       0.41      0.28      0.33      1236\n",
      "           4       0.82      0.81      0.81      3868\n",
      "\n",
      "    accuracy                           0.63     11984\n",
      "   macro avg       0.57      0.59      0.57     11984\n",
      "weighted avg       0.64      0.63      0.62     11984\n",
      "[[1103  159    4    1   12]\n",
      " [1011 2130  211   32   91]\n",
      " [  74  782  859  187  224]\n",
      " [  18  141  353  340  384]\n",
      " [ 157  150  141  274 3146]]\n",
      "\n",
      "Train............\n",
      "{'f1_score': 0.9996662130637665, 'prec_score': 0.9996666053924156, 'rec_score': 0.9996662216288384}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1279\n",
      "           1       1.00      1.00      1.00      3475\n",
      "           2       1.00      1.00      1.00      2126\n",
      "           3       1.00      1.00      1.00      1236\n",
      "           4       1.00      1.00      1.00      3868\n",
      "\n",
      "    accuracy                           1.00     11984\n",
      "   macro avg       1.00      1.00      1.00     11984\n",
      "weighted avg       1.00      1.00      1.00     11984\n",
      "[[1277    2    0    0    0]\n",
      " [   0 3475    0    0    0]\n",
      " [   0    2 2124    0    0]\n",
      " [   0    0    0 1236    0]\n",
      " [   0    0    0    0 3868]]\n",
      "\n",
      "Test............\n",
      "{'f1_score': 0.6348463005915278, 'prec_score': 0.663631356797864, 'rec_score': 0.6418277382163445}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.42      0.57      2277\n",
      "           1       0.59      0.71      0.64      3169\n",
      "           2       0.48      0.51      0.50      1748\n",
      "           3       0.36      0.34      0.35      1078\n",
      "           4       0.78      0.88      0.83      3524\n",
      "\n",
      "    accuracy                           0.64     11796\n",
      "   macro avg       0.62      0.57      0.58     11796\n",
      "weighted avg       0.66      0.64      0.63     11796\n",
      "[[ 957 1136   42    1  141]\n",
      " [ 115 2263  604   73  114]\n",
      " [   4  333  899  335  177]\n",
      " [   0   66  213  368  431]\n",
      " [  20   64  103  253 3084]]\n",
      "\n",
      "Train............\n",
      "{'f1_score': 0.9998337277122443, 'prec_score': 0.9998337854760004, 'rec_score': 0.9998337351400781}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2868\n",
      "           1       1.00      1.00      1.00      3891\n",
      "           2       1.00      1.00      1.00      2021\n",
      "           3       1.00      1.00      1.00      1112\n",
      "           4       1.00      1.00      1.00      2137\n",
      "\n",
      "    accuracy                           1.00     12029\n",
      "   macro avg       1.00      1.00      1.00     12029\n",
      "weighted avg       1.00      1.00      1.00     12029\n",
      "[[2868    0    0    0    0]\n",
      " [   0 3891    0    0    0]\n",
      " [   0    1 2020    0    0]\n",
      " [   0    0    0 1112    0]\n",
      " [   1    0    0    0 2136]]\n",
      "\n",
      "Test............\n",
      "{'f1_score': 0.6785663298524218, 'prec_score': 0.6966339532567236, 'rec_score': 0.6707789284106258}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.69      0.77      2962\n",
      "           1       0.64      0.74      0.68      3259\n",
      "           2       0.45      0.52      0.48      1606\n",
      "           3       0.36      0.40      0.38       936\n",
      "           4       0.87      0.76      0.81      2342\n",
      "\n",
      "    accuracy                           0.67     11105\n",
      "   macro avg       0.64      0.62      0.63     11105\n",
      "weighted avg       0.70      0.67      0.68     11105\n",
      "[[2041  884   28    6    3]\n",
      " [ 213 2406  580   41   19]\n",
      " [  20  386  841  297   62]\n",
      " [  11   50  308  373  194]\n",
      " [  58   56  129  311 1788]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "df=experiment('dis_rf',city,rf_model_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e3d46f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score_train</th>\n",
       "      <th>prec_score_train</th>\n",
       "      <th>rec_score_train</th>\n",
       "      <th>f1_score_test</th>\n",
       "      <th>prec_score_test</th>\n",
       "      <th>rec_score_test</th>\n",
       "      <th>train_dev</th>\n",
       "      <th>test_dev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.545881</td>\n",
       "      <td>0.582272</td>\n",
       "      <td>0.546835</td>\n",
       "      <td>[30]</td>\n",
       "      <td>[18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999750</td>\n",
       "      <td>0.999750</td>\n",
       "      <td>0.999750</td>\n",
       "      <td>0.677213</td>\n",
       "      <td>0.675520</td>\n",
       "      <td>0.684228</td>\n",
       "      <td>[23]</td>\n",
       "      <td>[20]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.588955</td>\n",
       "      <td>0.591939</td>\n",
       "      <td>0.588991</td>\n",
       "      <td>[25]</td>\n",
       "      <td>[22]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.999834</td>\n",
       "      <td>0.999834</td>\n",
       "      <td>0.999834</td>\n",
       "      <td>0.727667</td>\n",
       "      <td>0.748783</td>\n",
       "      <td>0.722310</td>\n",
       "      <td>[24]</td>\n",
       "      <td>[23]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.999750</td>\n",
       "      <td>0.999750</td>\n",
       "      <td>0.999750</td>\n",
       "      <td>0.665132</td>\n",
       "      <td>0.680390</td>\n",
       "      <td>0.681520</td>\n",
       "      <td>[23]</td>\n",
       "      <td>[24]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.565123</td>\n",
       "      <td>0.567152</td>\n",
       "      <td>0.577050</td>\n",
       "      <td>[22]</td>\n",
       "      <td>[25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.634232</td>\n",
       "      <td>0.643972</td>\n",
       "      <td>0.630945</td>\n",
       "      <td>[30]</td>\n",
       "      <td>[28]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.999715</td>\n",
       "      <td>0.999716</td>\n",
       "      <td>0.999715</td>\n",
       "      <td>0.516969</td>\n",
       "      <td>0.555755</td>\n",
       "      <td>0.525728</td>\n",
       "      <td>[18]</td>\n",
       "      <td>[30]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.640633</td>\n",
       "      <td>0.648580</td>\n",
       "      <td>0.641047</td>\n",
       "      <td>[30]</td>\n",
       "      <td>[33]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.624597</td>\n",
       "      <td>0.636027</td>\n",
       "      <td>0.632343</td>\n",
       "      <td>[35]</td>\n",
       "      <td>[34]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.999666</td>\n",
       "      <td>0.999667</td>\n",
       "      <td>0.999666</td>\n",
       "      <td>0.634846</td>\n",
       "      <td>0.663631</td>\n",
       "      <td>0.641828</td>\n",
       "      <td>[34]</td>\n",
       "      <td>[35]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.999834</td>\n",
       "      <td>0.999834</td>\n",
       "      <td>0.999834</td>\n",
       "      <td>0.678566</td>\n",
       "      <td>0.696634</td>\n",
       "      <td>0.670779</td>\n",
       "      <td>[24]</td>\n",
       "      <td>[37]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    f1_score_train  prec_score_train  rec_score_train  f1_score_test  \\\n",
       "0         0.999915          0.999915         0.999915       0.545881   \n",
       "1         0.999750          0.999750         0.999750       0.677213   \n",
       "2         1.000000          1.000000         1.000000       0.588955   \n",
       "3         0.999834          0.999834         0.999834       0.727667   \n",
       "4         0.999750          0.999750         0.999750       0.665132   \n",
       "5         1.000000          1.000000         1.000000       0.565123   \n",
       "6         0.999915          0.999915         0.999915       0.634232   \n",
       "7         0.999715          0.999716         0.999715       0.516969   \n",
       "8         0.999915          0.999915         0.999915       0.640633   \n",
       "9         1.000000          1.000000         1.000000       0.624597   \n",
       "10        0.999666          0.999667         0.999666       0.634846   \n",
       "11        0.999834          0.999834         0.999834       0.678566   \n",
       "\n",
       "    prec_score_test  rec_score_test train_dev test_dev  \n",
       "0          0.582272        0.546835      [30]     [18]  \n",
       "1          0.675520        0.684228      [23]     [20]  \n",
       "2          0.591939        0.588991      [25]     [22]  \n",
       "3          0.748783        0.722310      [24]     [23]  \n",
       "4          0.680390        0.681520      [23]     [24]  \n",
       "5          0.567152        0.577050      [22]     [25]  \n",
       "6          0.643972        0.630945      [30]     [28]  \n",
       "7          0.555755        0.525728      [18]     [30]  \n",
       "8          0.648580        0.641047      [30]     [33]  \n",
       "9          0.636027        0.632343      [35]     [34]  \n",
       "10         0.663631        0.641828      [34]     [35]  \n",
       "11         0.696634        0.670779      [24]     [37]  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "653197f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RNN\n",
    "df=experiment('dis_rnn',city,rnn_model_fn,epochs=epochs,batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a249f4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ffc8a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NICE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
